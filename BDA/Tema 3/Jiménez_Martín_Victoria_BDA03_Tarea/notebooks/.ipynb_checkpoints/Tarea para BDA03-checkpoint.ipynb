{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plantilla para la Tarea online BDA03\n",
    "\n",
    "# Nombre del alumno: Victoria Jiménez Martín\n",
    "\n",
    "Realiza las tareas que se plantean en cada ejercicio. En algunas tareas deberás completar las celdas que están incompletas en otras añadir nuevas celdas. Se trata de que implementes una serie de consultas con HQL (Hive) y Pig Latin.\n",
    "\n",
    "Vamos a seguir utilizando el `dataset` de retrasos en vuelos en EEUU de la guía práctica. A modo de recordatorio, en el siguiente apartado, repetimos la explicación del significado de los campos.\n",
    "\n",
    "# Dataset de retrasos en vuelos\n",
    "\n",
    "Vamos a usar [este](https://www.kaggle.com/datasets/tylerx/flights-and-airports-data) de Kaggle\n",
    "para aprender a usar tanto Hive como Pig. Kaggle es un sitio muy popular en ciencia de datos. En este sitio los científicos de datos pueden publicar y compartir sus trabajos. Además también se pueden proponer concursos en los que los participantes compiten en la construcción del mejor modelo para el problema propuesto.\n",
    "\n",
    "El `dataset` contiene información sobre retrasos en vuelos en EEUU. Hay dos ficheros de interés: `airports.csv` y `flights.csv`.\n",
    "\n",
    "El primero tiene información sobre los aeropuertos y consta de los siguientes campos:\n",
    "   * airport_id: identificador del aeropuerto. Numérico, aunque se utilizará un campo `string` en Hive.\n",
    "   * city: ciudad del aeropuerto.\n",
    "   * state: estado del aeropuerto.\n",
    "   * name: nombre del aeropuerto.\n",
    "   \n",
    "El fichero `flights` tiene la siguiente estructura:\n",
    "   * DayofMonth: día del mes del vuelo.\n",
    "   * DayOfWeek: día de la semana del vuelo.\n",
    "   * Carrier: Identificador de la compañía aérea.\n",
    "   * OriginAirportID: Identificador del aeropuerto de origen.\n",
    "   * DestAirportID: Identificador del aeropuerto de destino.\n",
    "   * DepDelay: Minutos de retraso en la salida de un vuelo (puede ser negativo si el vuelo sale antes de lo previsto).\n",
    "   * ArrDelay: Minutos de retraso en la llegada de un vuelo (puede ser negativo si el vuelo sale antes de lo previsto).\n",
    "\n",
    "El directorio `notebooks` contiene el `archiv.zip` con los dos ficheros. Para descargarlo de Kaggle hay que estar registrado y se ha incluido para que no tengas que registrarte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.- Realiza el proceso de preparación que se hizo en la guia práctica:\n",
    "\n",
    "* Crea las celdas y muestra el resultado de su ejecución de la extracción de los ficheros del `dataset` de vuelos.\n",
    "* Crea la base de datos de Hive y las tablas `airports` y `flights`. Presta atención a cambiar los comentarios y no simplemente copiar los de la guía.\n",
    "* Carga las tablas y crea consultas de HQL que muestren 10 aeropuertos y 10 vuelos como se hizo en la guía práctica.\n",
    "* Crea un `script` en Pig Latin que muestre 10 aeropuertos y 10 vuelos como se hizo en la guía práctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 http://archive.ubuntu.com/ubuntu focal InRelease\n",
      "Hit:2 http://security.ubuntu.com/ubuntu focal-security InRelease\n",
      "Hit:3 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu focal-backports InRelease\n",
      "Reading package lists... Done3m\u001b[33m\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "207 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
     ]
    }
   ],
   "source": [
    "# Lo primero que haremos será actualizar el entorno\n",
    "\n",
    "! apt update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "unzip is already the newest version (6.0-25ubuntu1.2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 207 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "# Instalamos el unzip\n",
    "\n",
    "! apt install unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  archive.zip\n",
      "  inflating: airports.csv            \n",
      "  inflating: flights.csv             \n"
     ]
    }
   ],
   "source": [
    "# Descomprimimos los archivos\n",
    "\n",
    "! unzip -j -o archive.zip airports.csv flights.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366 airports.csv\r\n",
      "airport_id,city,state,name\r",
      "\r\n",
      "10165,Adak Island,AK,Adak\r",
      "\r\n",
      "10299,Anchorage,AK,Ted Stevens Anchorage International\r",
      "\r\n",
      "10304,Aniak,AK,Aniak Airport\r",
      "\r\n",
      "10754,Barrow,AK,Wiley Post/Will Rogers Memorial\r",
      "\r\n",
      "10551,Bethel,AK,Bethel Airport\r",
      "\r\n",
      "10926,Cordova,AK,Merle K Mudhole Smith\r",
      "\r\n",
      "14709,Deadhorse,AK,Deadhorse Airport\r",
      "\r\n",
      "11336,Dillingham,AK,Dillingham Airport\r",
      "\r\n",
      "11630,Fairbanks,AK,Fairbanks International\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# Leemos el numero de lineas y primeras lineas del fichero de airports.csv\n",
    "! wc -l airports.csv && head airports.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2702219 flights.csv\r\n",
      "DayofMonth,DayOfWeek,Carrier,OriginAirportID,DestAirportID,DepDelay,ArrDelay\r",
      "\r\n",
      "19,5,DL,11433,13303,-3,1\r",
      "\r\n",
      "19,5,DL,14869,12478,0,-8\r",
      "\r\n",
      "19,5,DL,14057,14869,-4,-15\r",
      "\r\n",
      "19,5,DL,15016,11433,28,24\r",
      "\r\n",
      "19,5,DL,11193,12892,-6,-11\r",
      "\r\n",
      "19,5,DL,10397,15016,-1,-19\r",
      "\r\n",
      "19,5,DL,15016,10397,0,-1\r",
      "\r\n",
      "19,5,DL,10397,14869,15,24\r",
      "\r\n",
      "19,5,DL,10397,10423,33,34\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# Leemos el numero de lineas y primeras lineas del fichero de flights.csv\n",
    "! wc -l flights.csv && head flights.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   3 root supergroup      16308 2024-02-17 01:01 /user/root/flights/airports.csv\r\n",
      "-rw-r--r--   3 root supergroup   72088113 2024-02-17 01:01 /user/root/flights/flights.csv\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -mkdir -p /user/root/flights\n",
    "! hdfs dfs -put -f ./airports.csv /user/root/flights\n",
    "! hdfs dfs -put -f ./flights.csv /user/root/flights\n",
    "! hdfs dfs -ls /user/root/flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240217010123_dd6ffd58-0dce-4729-9e34-50bb3e3e1998): SHOW DATABASES\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:database_name, type:string, comment:from deserializer)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240217010123_dd6ffd58-0dce-4729-9e34-50bb3e3e1998); Time taken: 0.013 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240217010123_dd6ffd58-0dce-4729-9e34-50bb3e3e1998): SHOW DATABASES\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20240217010123_dd6ffd58-0dce-4729-9e34-50bb3e3e1998); Time taken: 0.026 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+----------------+\n",
      "| database_name  |\n",
      "+----------------+\n",
      "| bda03          |\n",
      "| default        |\n",
      "+----------------+\n",
      "2 rows selected (0.113 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000\n"
     ]
    }
   ],
   "source": [
    "# Para comprobar que se conecta a Hive, ejecutamos el siguiente comando para que nos muestre las\n",
    "# bases de datos disponibles\n",
    "! beeline -u \"jdbc:hive2://localhost:10000\" -e \"SHOW DATABASES\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240217010135_99a6171d-1de3-41d6-8d4d-d407edf81835): CREATE DATABASE IF NOT EXISTS bda03  COMMENT 'Base de datos de la unidad BDA03'  WITH DBPROPERTIES ('Creada por' = 'Victoria Jim?nez', 'Fecha' = '13/02/24')\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240217010135_99a6171d-1de3-41d6-8d4d-d407edf81835); Time taken: 0.01 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240217010135_99a6171d-1de3-41d6-8d4d-d407edf81835): CREATE DATABASE IF NOT EXISTS bda03  COMMENT 'Base de datos de la unidad BDA03'  WITH DBPROPERTIES ('Creada por' = 'Victoria Jim?nez', 'Fecha' = '13/02/24')\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20240217010135_99a6171d-1de3-41d6-8d4d-d407edf81835); Time taken: 0.104 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.18 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/\n"
     ]
    }
   ],
   "source": [
    "# Creamos una base de datos nueva\n",
    "! beeline -u \"jdbc:hive2://localhost:10000/\" -e \"CREATE DATABASE IF NOT EXISTS bda03 \\\n",
    "COMMENT 'Base de datos de la unidad BDA03' \\\n",
    "WITH DBPROPERTIES ('Creada por' = 'Victoria Jiménez', 'Fecha' = '13/02/24');\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240217010147_a86e5c0e-35e0-4b00-8f5b-5d091539f5cd): DROP TABLE IF EXISTS airports\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240217010147_a86e5c0e-35e0-4b00-8f5b-5d091539f5cd); Time taken: 0.065 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240217010147_a86e5c0e-35e0-4b00-8f5b-5d091539f5cd): DROP TABLE IF EXISTS airports\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20240217010147_a86e5c0e-35e0-4b00-8f5b-5d091539f5cd); Time taken: 0.435 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.603 seconds)\n",
      "INFO  : Compiling command(queryId=root_20240217010148_8bb21a88-5c20-48ae-995e-751e547b0625): CREATE EXTERNAL TABLE IF NOT EXISTS airports (airportid STRING, city STRING, state STRING, airportname STRING)  COMMENT 'USA Airports' ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\,'  TBLPROPERTIES ('Autora' = 'Victoria Jim?nez', 'Fecha' = '13/02/24', 'skip.header.line.count' = '1')\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240217010148_8bb21a88-5c20-48ae-995e-751e547b0625); Time taken: 0.064 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240217010148_8bb21a88-5c20-48ae-995e-751e547b0625): CREATE EXTERNAL TABLE IF NOT EXISTS airports (airportid STRING, city STRING, state STRING, airportname STRING)  COMMENT 'USA Airports' ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\,'  TBLPROPERTIES ('Autora' = 'Victoria Jim?nez', 'Fecha' = '13/02/24', 'skip.header.line.count' = '1')\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20240217010148_8bb21a88-5c20-48ae-995e-751e547b0625); Time taken: 0.382 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.534 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "# Creamos una tabla nueva\n",
    "! beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \"DROP TABLE IF EXISTS airports; \\\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS airports (airportid STRING, city STRING, state STRING, airportname STRING) \\\n",
    "COMMENT 'USA Airports' ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\,' \\\n",
    "TBLPROPERTIES ('Autora' = 'Victoria Jiménez', 'Fecha' = '13/02/24', 'skip.header.line.count' = '1');\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240217010200_ea619836-4ba9-4f56-8503-326b73955f5d): DROP TABLE IF EXISTS flights\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240217010200_ea619836-4ba9-4f56-8503-326b73955f5d); Time taken: 0.086 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240217010200_ea619836-4ba9-4f56-8503-326b73955f5d): DROP TABLE IF EXISTS flights\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20240217010200_ea619836-4ba9-4f56-8503-326b73955f5d); Time taken: 0.422 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.603 seconds)\n",
      "INFO  : Compiling command(queryId=root_20240217010200_b09ab672-7f4a-453b-b08f-87f8e8480c2c): CREATE EXTERNAL TABLE IF NOT EXISTS flights (dayofmonth TINYINT, dayofweek TINYINT, carrier STRING,  depairportid STRING, arrairportid STRING, depdelay SMALLINT, arrdelay SMALLINT)  COMMENT 'Flights' ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\,'  TBLPROPERTIES ('Autora' = 'Victoria Jim?nez', 'Fecha' = '13/02/24', 'skip.header.line.count' = '1')\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240217010200_b09ab672-7f4a-453b-b08f-87f8e8480c2c); Time taken: 0.029 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240217010200_b09ab672-7f4a-453b-b08f-87f8e8480c2c): CREATE EXTERNAL TABLE IF NOT EXISTS flights (dayofmonth TINYINT, dayofweek TINYINT, carrier STRING,  depairportid STRING, arrairportid STRING, depdelay SMALLINT, arrdelay SMALLINT)  COMMENT 'Flights' ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\,'  TBLPROPERTIES ('Autora' = 'Victoria Jim?nez', 'Fecha' = '13/02/24', 'skip.header.line.count' = '1')\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20240217010200_b09ab672-7f4a-453b-b08f-87f8e8480c2c); Time taken: 0.225 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.31 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "# Creamos una tabla nueva\n",
    "! beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \"DROP TABLE IF EXISTS flights; \\\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS flights (dayofmonth TINYINT, dayofweek TINYINT, carrier STRING, \\\n",
    "depairportid STRING, arrairportid STRING, depdelay SMALLINT, arrdelay SMALLINT) \\\n",
    "COMMENT 'Flights' ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\,' \\\n",
    "TBLPROPERTIES ('Autora' = 'Victoria Jiménez', 'Fecha' = '13/02/24', 'skip.header.line.count' = '1');\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos permisos al directorio\n",
    "! hdfs dfs -chmod 777 /user/root/flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240217010217_34a876b0-9576-4efd-84ea-966b9e0d6349): LOAD DATA INPATH '/user/root/flights/airports.csv'  OVERWRITE INTO TABLE airports\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240217010217_34a876b0-9576-4efd-84ea-966b9e0d6349); Time taken: 0.072 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240217010217_34a876b0-9576-4efd-84ea-966b9e0d6349): LOAD DATA INPATH '/user/root/flights/airports.csv'  OVERWRITE INTO TABLE airports\n",
      "INFO  : Starting task [Stage-0:MOVE] in serial mode\n",
      "INFO  : Loading data to table bda03.airports from hdfs://namenode:8020/user/root/flights/airports.csv\n",
      "INFO  : Starting task [Stage-1:STATS] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20240217010217_34a876b0-9576-4efd-84ea-966b9e0d6349); Time taken: 0.66 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.816 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el csv en la tabla\n",
    "! beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \"LOAD DATA INPATH '/user/root/flights/airports.csv' \\\n",
    "OVERWRITE INTO TABLE airports;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240217010232_70b0aa88-4f5b-4d7f-b52a-54dd6530b18c): LOAD DATA INPATH '/user/root/flights/flights.csv'  OVERWRITE INTO TABLE flights\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240217010232_70b0aa88-4f5b-4d7f-b52a-54dd6530b18c); Time taken: 0.049 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240217010232_70b0aa88-4f5b-4d7f-b52a-54dd6530b18c): LOAD DATA INPATH '/user/root/flights/flights.csv'  OVERWRITE INTO TABLE flights\n",
      "INFO  : Starting task [Stage-0:MOVE] in serial mode\n",
      "INFO  : Loading data to table bda03.flights from hdfs://namenode:8020/user/root/flights/flights.csv\n",
      "INFO  : Starting task [Stage-1:STATS] in serial mode\n",
      "INFO  : Completed executing command(queryId=root_20240217010232_70b0aa88-4f5b-4d7f-b52a-54dd6530b18c); Time taken: 0.336 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (0.476 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el csv en la tabla\n",
    "! beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \"LOAD DATA INPATH '/user/root/flights/flights.csv' \\\n",
    "OVERWRITE INTO TABLE flights;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240217010239_a0cbb21a-5077-4d0f-a16c-41833878e8f3): SELECT * FROM airports LIMIT 10\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:airports.airportid, type:string, comment:null), FieldSchema(name:airports.city, type:string, comment:null), FieldSchema(name:airports.state, type:string, comment:null), FieldSchema(name:airports.airportname, type:string, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240217010239_a0cbb21a-5077-4d0f-a16c-41833878e8f3); Time taken: 0.191 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240217010239_a0cbb21a-5077-4d0f-a16c-41833878e8f3): SELECT * FROM airports LIMIT 10\n",
      "INFO  : Completed executing command(queryId=root_20240217010239_a0cbb21a-5077-4d0f-a16c-41833878e8f3); Time taken: 0.0 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+---------------------+----------------+-----------------+--------------------------------------+\n",
      "| airports.airportid  | airports.city  | airports.state  |         airports.airportname         |\n",
      "+---------------------+----------------+-----------------+--------------------------------------+\n",
      "| 10165               | Adak Island    | AK              | Adak                                 |\n",
      "| 10299               | Anchorage      | AK              | Ted Stevens Anchorage International  |\n",
      "| 10304               | Aniak          | AK              | Aniak Airport                        |\n",
      "| 10754               | Barrow         | AK              | Wiley Post/Will Rogers Memorial      |\n",
      "| 10551               | Bethel         | AK              | Bethel Airport                       |\n",
      "| 10926               | Cordova        | AK              | Merle K Mudhole Smith                |\n",
      "| 14709               | Deadhorse      | AK              | Deadhorse Airport                    |\n",
      "| 11336               | Dillingham     | AK              | Dillingham Airport                   |\n",
      "| 11630               | Fairbanks      | AK              | Fairbanks International              |\n",
      "| 11997               | Gustavus       | AK              | Gustavus Airport                     |\n",
      "+---------------------+----------------+-----------------+--------------------------------------+\n",
      "10 rows selected (0.355 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "# Cargamos 10 aeropuestos\n",
    "! beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \"SELECT * FROM airports LIMIT 10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240217010254_9fa8a1d5-1418-40b1-9655-bc5631db4e8d): SELECT * FROM flights LIMIT 10\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:flights.dayofmonth, type:tinyint, comment:null), FieldSchema(name:flights.dayofweek, type:tinyint, comment:null), FieldSchema(name:flights.carrier, type:string, comment:null), FieldSchema(name:flights.depairportid, type:string, comment:null), FieldSchema(name:flights.arrairportid, type:string, comment:null), FieldSchema(name:flights.depdelay, type:smallint, comment:null), FieldSchema(name:flights.arrdelay, type:smallint, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240217010254_9fa8a1d5-1418-40b1-9655-bc5631db4e8d); Time taken: 0.435 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240217010254_9fa8a1d5-1418-40b1-9655-bc5631db4e8d): SELECT * FROM flights LIMIT 10\n",
      "INFO  : Completed executing command(queryId=root_20240217010254_9fa8a1d5-1418-40b1-9655-bc5631db4e8d); Time taken: 0.0 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+---------------------+--------------------+------------------+-----------------------+-----------------------+-------------------+-------------------+\n",
      "| flights.dayofmonth  | flights.dayofweek  | flights.carrier  | flights.depairportid  | flights.arrairportid  | flights.depdelay  | flights.arrdelay  |\n",
      "+---------------------+--------------------+------------------+-----------------------+-----------------------+-------------------+-------------------+\n",
      "| 19                  | 5                  | DL               | 11433                 | 13303                 | -3                | 1                 |\n",
      "| 19                  | 5                  | DL               | 14869                 | 12478                 | 0                 | -8                |\n",
      "| 19                  | 5                  | DL               | 14057                 | 14869                 | -4                | -15               |\n",
      "| 19                  | 5                  | DL               | 15016                 | 11433                 | 28                | 24                |\n",
      "| 19                  | 5                  | DL               | 11193                 | 12892                 | -6                | -11               |\n",
      "| 19                  | 5                  | DL               | 10397                 | 15016                 | -1                | -19               |\n",
      "| 19                  | 5                  | DL               | 15016                 | 10397                 | 0                 | -1                |\n",
      "| 19                  | 5                  | DL               | 10397                 | 14869                 | 15                | 24                |\n",
      "| 19                  | 5                  | DL               | 10397                 | 10423                 | 33                | 34                |\n",
      "| 19                  | 5                  | DL               | 11278                 | 10397                 | 323               | 322               |\n",
      "+---------------------+--------------------+------------------+-----------------------+-----------------------+-------------------+-------------------+\n",
      "10 rows selected (0.713 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "# Muestra 10 vuelos\n",
    "! beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \"SELECT * FROM flights LIMIT 10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing flights.pig\n"
     ]
    }
   ],
   "source": [
    "%%writefile flights.pig\n",
    "\n",
    "-- resgistramos la librería PiggyBank para poder usar la función de carga CSVExcelStorage.\n",
    "REGISTER piggybank.jar\n",
    "\n",
    "/*\n",
    "Leemos el fichero de airports.csv.\n",
    "\n",
    "Usamos el loader CSVExcelStorage indicando el delimitador (,) y que se debe excluir la cabecera.\n",
    "*/\n",
    "\n",
    "AIRPORTS = LOAD '$airports_file' USING\n",
    "       org.apache.pig.piggybank.storage.CSVExcelStorage(',', 'NO_MULTILINE', 'UNIX', 'SKIP_INPUT_HEADER')\n",
    "       AS (airportid:chararray, city:chararray, state:chararray, airportname:chararray);\n",
    "\n",
    "-- Leemos el fichero fligths.csv\n",
    "\n",
    "FLIGHTS = LOAD '$flights_file' USING\n",
    "       org.apache.pig.piggybank.storage.CSVExcelStorage(',', 'NO_MULTILINE', 'UNIX', 'SKIP_INPUT_HEADER')\n",
    "       AS (dayofmonth:int, dayofweek:int, carrier:chararray, \n",
    "               depairportid:chararray, arrairportid:chararray, depdelay:int, arrdelay:int);\n",
    "\n",
    "\n",
    "-- Probamos que podemos recuperar datos.\n",
    "      \n",
    "-- Nos quedamos con 10 aeropuertos\n",
    "AIRPORTS_10 = LIMIT AIRPORTS 10;\n",
    "\n",
    "-- Mostramos 10 aeropuertos\n",
    "DUMP AIRPORTS_10;\n",
    "\n",
    "-- Hacemos lo mismo con los vuelos\n",
    "FLIGHTS_10 = LIMIT FLIGHTS 10;\n",
    "DUMP FLIGHTS_10;\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-13 23:12:47,084 INFO pig.ExecTypeProvider: Trying ExecType : LOCAL\n",
      "2024-02-13 23:12:47,084 INFO pig.ExecTypeProvider: Picked LOCAL as the ExecType\n",
      "2024-02-13 23:12:47,129 [main] INFO  org.apache.pig.Main - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58\n",
      "2024-02-13 23:12:47,129 [main] INFO  org.apache.pig.Main - Logging error messages to: /media/notebooks/Tarea 3/notebooks/pig_1707862367128.log\n",
      "2024-02-13 23:12:47,141 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - user.name is deprecated. Instead, use mapreduce.job.user.name\n",
      "2024-02-13 23:12:47,237 [main] INFO  org.apache.pig.impl.util.Utils - Default bootup file /root/.pigbootup not found\n",
      "2024-02-13 23:12:47,277 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-02-13 23:12:47,278 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine - Connecting to hadoop file system at: file:///\n",
      "2024-02-13 23:12:47,295 [main] INFO  org.apache.pig.PigServer - Pig Script ID for the session: PIG-flights.pig-a242cfd8-b409-4697-b4ce-5ab8b5f73d1b\n",
      "2024-02-13 23:12:47,295 [main] WARN  org.apache.pig.PigServer - ATS is disabled since yarn.timeline-service.enabled set to false\n",
      "2024-02-13 23:12:47,680 [main] INFO  org.apache.pig.tools.pigstats.ScriptState - Pig features used in the script: LIMIT\n",
      "2024-02-13 23:12:47,724 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}\n",
      "2024-02-13 23:12:47,793 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-13 23:12:47,854 [main] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-13 23:12:47,854 [main] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-13 23:12:47,904 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-13 23:12:47,910 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-13 23:12:47,912 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-02-13 23:12:47,943 [main] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt__0001_m_000001_1' to file:/tmp/temp1081278919/tmp2056136879\n",
      "2024-02-13 23:12:47,948 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-13 23:12:47,954 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-13 23:12:47,955 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "(10165,Adak Island,AK,Adak)\n",
      "(10299,Anchorage,AK,Ted Stevens Anchorage International)\n",
      "(10304,Aniak,AK,Aniak Airport)\n",
      "(10754,Barrow,AK,Wiley Post/Will Rogers Memorial)\n",
      "(10551,Bethel,AK,Bethel Airport)\n",
      "(10926,Cordova,AK,Merle K Mudhole Smith)\n",
      "(14709,Deadhorse,AK,Deadhorse Airport)\n",
      "(11336,Dillingham,AK,Dillingham Airport)\n",
      "(11630,Fairbanks,AK,Fairbanks International)\n",
      "(11997,Gustavus,AK,Gustavus Airport)\n",
      "2024-02-13 23:12:47,986 [main] INFO  org.apache.pig.tools.pigstats.ScriptState - Pig features used in the script: LIMIT\n",
      "2024-02-13 23:12:47,996 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-13 23:12:47,996 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}\n",
      "2024-02-13 23:12:48,011 [main] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-13 23:12:48,011 [main] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-13 23:12:48,027 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-13 23:12:48,029 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-13 23:12:48,029 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-02-13 23:12:48,034 [main] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt__0001_m_000001_1' to file:/tmp/temp1081278919/tmp1648666486\n",
      "2024-02-13 23:12:48,036 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-13 23:12:48,039 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-13 23:12:48,039 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "(19,5,DL,11433,13303,-3,1)\n",
      "(19,5,DL,14869,12478,0,-8)\n",
      "(19,5,DL,14057,14869,-4,-15)\n",
      "(19,5,DL,15016,11433,28,24)\n",
      "(19,5,DL,11193,12892,-6,-11)\n",
      "(19,5,DL,10397,15016,-1,-19)\n",
      "(19,5,DL,15016,10397,0,-1)\n",
      "(19,5,DL,10397,14869,15,24)\n",
      "(19,5,DL,10397,10423,33,34)\n",
      "(19,5,DL,11278,10397,323,322)\n",
      "2024-02-13 23:12:48,063 [main] INFO  org.apache.pig.Main - Pig script completed in 1 second and 84 milliseconds (1084 ms)\n"
     ]
    }
   ],
   "source": [
    "# Ejecutamos el script\n",
    "! pig -x local -f flights.pig -param airports_file='airports.csv' -param flights_file='flights.csv' -param output_dir='pig/output/flights'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.- Con una consulta de HQL muestra: La cinco compañías que más vuelos retrasados tienen.\n",
    "\n",
    "* El campo `carrier` contiene la compañía aérea.\n",
    "* Vamos a considerar que un vuelo llega con retraso cuando el vuelo llega más de 15 minutos tarde (campo `arrdelay` > 15).\n",
    "\n",
    "Se espera el siguiente resultado:\n",
    "\n",
    "![solución 2](./img/2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240217003157_98fc1f4f-6e33-4680-8806-fb8ee8933661): SELECT carrier, COUNT(*) as total_retrasos FROM flights WHERE arrdelay > 15 GROUP BY carrier ORDER BY total_retrasos DESC LIMIT 5\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:carrier, type:string, comment:null), FieldSchema(name:total_retrasos, type:bigint, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240217003157_98fc1f4f-6e33-4680-8806-fb8ee8933661); Time taken: 3.392 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240217003157_98fc1f4f-6e33-4680-8806-fb8ee8933661): SELECT carrier, COUNT(*) as total_retrasos FROM flights WHERE arrdelay > 15 GROUP BY carrier ORDER BY total_retrasos DESC LIMIT 5\n",
      "WARN  : Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.\n",
      "INFO  : Query ID = root_20240217003157_98fc1f4f-6e33-4680-8806-fb8ee8933661\n",
      "INFO  : Total jobs = 2\n",
      "INFO  : Launching Job 1 out of 2\n",
      "INFO  : Starting task [Stage-1:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1708124468755_0001\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1708124468755_0001/\n",
      "INFO  : Starting Job = job_1708124468755_0001, Tracking URL = http://yarnmaster:8088/proxy/application_1708124468755_0001/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1708124468755_0001\n",
      "INFO  : Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2024-02-17 00:32:15,428 Stage-1 map = 0%,  reduce = 0%\n",
      "INFO  : 2024-02-17 00:32:27,012 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 5.06 sec\n",
      "INFO  : 2024-02-17 00:32:33,360 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 7.03 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 7 seconds 30 msec\n",
      "INFO  : Ended Job = job_1708124468755_0001\n",
      "INFO  : Launching Job 2 out of 2\n",
      "INFO  : Starting task [Stage-2:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks determined at compile time: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1708124468755_0002\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1708124468755_0002/\n",
      "INFO  : Starting Job = job_1708124468755_0002, Tracking URL = http://yarnmaster:8088/proxy/application_1708124468755_0002/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1708124468755_0002\n",
      "INFO  : Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2024-02-17 00:32:41,936 Stage-2 map = 0%,  reduce = 0%\n",
      "INFO  : 2024-02-17 00:32:47,299 Stage-2 map = 100%,  reduce = 0%\n",
      "INFO  : 2024-02-17 00:32:56,691 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 2.62 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 2 seconds 620 msec\n",
      "INFO  : Ended Job = job_1708124468755_0002\n",
      "INFO  : MapReduce Jobs Launched: \n",
      "INFO  : Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 7.03 sec   HDFS Read: 72103097 HDFS Write: 465 SUCCESS\n",
      "INFO  : Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 2.62 sec   HDFS Read: 8080 HDFS Write: 193 SUCCESS\n",
      "INFO  : Total MapReduce CPU Time Spent: 9 seconds 650 msec\n",
      "INFO  : Completed executing command(queryId=root_20240217003157_98fc1f4f-6e33-4680-8806-fb8ee8933661); Time taken: 56.852 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+----------+-----------------+\n",
      "| carrier  | total_retrasos  |\n",
      "+----------+-----------------+\n",
      "| WN       | 127601          |\n",
      "| AA       | 59842           |\n",
      "| DL       | 57668           |\n",
      "| UA       | 57367           |\n",
      "| US       | 40943           |\n",
      "+----------+-----------------+\n",
      "5 rows selected (60.664 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \"SELECT carrier, COUNT(*) as total_retrasos \\\n",
    "FROM flights WHERE arrdelay > 15 \\\n",
    "GROUP BY carrier \\\n",
    "ORDER BY total_retrasos \\\n",
    "DESC LIMIT 5;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.- Con una consulta de HQL muestra: Las 5 compañías que mejor recuperación de tiempo en vuelo tienen.\n",
    "\n",
    "* Se considera que se ha recuperado el tiempo de un vuelo cuando habiendo salido con retraso (`depdelay` > 15), llega sin retraso (`arraydelay` <= 15).\n",
    "* Se trata de que muestres las 5 compañías que han recuperado el tiempo en un mayor porcentaje de vuelos que salieron retrasados.\n",
    "\n",
    "El resultado esperado es el siguiente:\n",
    "\n",
    "![solución 3](./img/3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://localhost:10000/bda03\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 3.1.2)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "INFO  : Compiling command(queryId=root_20240217013255_e77c7792-c4be-4646-9638-89f196160ec8): SELECT carrier,         CAST(COUNT(CASE WHEN depdelay > 15 AND arrdelay <= 15 THEN 1 ELSE NULL END) AS FLOAT)         / CAST(COUNT(CASE WHEN depdelay > 15 THEN 1 ELSE NULL END) AS FLOAT) AS porcentaje_recuperacion  FROM flights  WHERE depdelay > 15  GROUP BY carrier  HAVING COUNT(CASE WHEN depdelay > 15 THEN 1 ELSE NULL END) > 0  ORDER BY porcentaje_recuperacion DESC  LIMIT 5\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:carrier, type:string, comment:null), FieldSchema(name:porcentaje_recuperacion, type:double, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=root_20240217013255_e77c7792-c4be-4646-9638-89f196160ec8); Time taken: 0.316 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=root_20240217013255_e77c7792-c4be-4646-9638-89f196160ec8): SELECT carrier,         CAST(COUNT(CASE WHEN depdelay > 15 AND arrdelay <= 15 THEN 1 ELSE NULL END) AS FLOAT)         / CAST(COUNT(CASE WHEN depdelay > 15 THEN 1 ELSE NULL END) AS FLOAT) AS porcentaje_recuperacion  FROM flights  WHERE depdelay > 15  GROUP BY carrier  HAVING COUNT(CASE WHEN depdelay > 15 THEN 1 ELSE NULL END) > 0  ORDER BY porcentaje_recuperacion DESC  LIMIT 5\n",
      "WARN  : Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.\n",
      "INFO  : Query ID = root_20240217013255_e77c7792-c4be-4646-9638-89f196160ec8\n",
      "INFO  : Total jobs = 2\n",
      "INFO  : Launching Job 1 out of 2\n",
      "INFO  : Starting task [Stage-1:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1708127420348_0016\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1708127420348_0016/\n",
      "INFO  : Starting Job = job_1708127420348_0016, Tracking URL = http://yarnmaster:8088/proxy/application_1708127420348_0016/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1708127420348_0016\n",
      "INFO  : Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2024-02-17 01:33:02,969 Stage-1 map = 0%,  reduce = 0%\n",
      "INFO  : 2024-02-17 01:33:10,304 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 3.11 sec\n",
      "INFO  : 2024-02-17 01:33:16,519 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 5.39 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 5 seconds 390 msec\n",
      "INFO  : Ended Job = job_1708127420348_0016\n",
      "INFO  : Launching Job 2 out of 2\n",
      "INFO  : Starting task [Stage-2:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks determined at compile time: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1708127420348_0017\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://yarnmaster:8088/proxy/application_1708127420348_0017/\n",
      "INFO  : Starting Job = job_1708127420348_0017, Tracking URL = http://yarnmaster:8088/proxy/application_1708127420348_0017/\n",
      "INFO  : Kill Command = /app/hadoop-3.3.1/bin/mapred job  -kill job_1708127420348_0017\n",
      "INFO  : Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2024-02-17 01:33:26,811 Stage-2 map = 0%,  reduce = 0%\n",
      "INFO  : 2024-02-17 01:33:31,050 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 1.13 sec\n",
      "INFO  : 2024-02-17 01:33:37,230 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 2.54 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 2 seconds 540 msec\n",
      "INFO  : Ended Job = job_1708127420348_0017\n",
      "INFO  : MapReduce Jobs Launched: \n",
      "INFO  : Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 5.39 sec   HDFS Read: 72105969 HDFS Write: 544 SUCCESS\n",
      "INFO  : Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 2.54 sec   HDFS Read: 8050 HDFS Write: 261 SUCCESS\n",
      "INFO  : Total MapReduce CPU Time Spent: 7 seconds 930 msec\n",
      "INFO  : Completed executing command(queryId=root_20240217013255_e77c7792-c4be-4646-9638-89f196160ec8); Time taken: 42.968 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+----------+--------------------------+\n",
      "| carrier  | porcentaje_recuperacion  |\n",
      "+----------+--------------------------+\n",
      "| UA       | 0.24507301133462678      |\n",
      "| WN       | 0.23570878543927196      |\n",
      "| FL       | 0.2265728843597696       |\n",
      "| DL       | 0.21578780710414067      |\n",
      "| AA       | 0.20162014676224854      |\n",
      "+----------+--------------------------+\n",
      "5 rows selected (43.352 seconds)\n",
      "Beeline version 3.1.2 by Apache Hive\n",
      "Closing: 0: jdbc:hive2://localhost:10000/bda03\n"
     ]
    }
   ],
   "source": [
    "! beeline -u \"jdbc:hive2://localhost:10000/bda03\" -e \"SELECT carrier, \\\n",
    "       CAST(COUNT(CASE WHEN depdelay > 15 AND arrdelay <= 15 THEN 1 ELSE NULL END) AS FLOAT) \\\n",
    "       / CAST(COUNT(CASE WHEN depdelay > 15 THEN 1 ELSE NULL END) AS FLOAT) AS porcentaje_recuperacion \\\n",
    "FROM flights \\\n",
    "WHERE depdelay > 15 \\\n",
    "GROUP BY carrier \\\n",
    "HAVING COUNT(CASE WHEN depdelay > 15 THEN 1 ELSE NULL END) > 0 \\\n",
    "ORDER BY porcentaje_recuperacion DESC \\\n",
    "LIMIT 5\";\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.- Resuelve el ejercicio 2 con Pig Latin\n",
    "\n",
    "El resultado esperado es:\n",
    "\n",
    "![solución 4](./img/4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ejercicio2.pig\n"
     ]
    }
   ],
   "source": [
    "%%writefile ejercicio2.pig\n",
    "\n",
    "REGISTER piggybank.jar\n",
    "\n",
    "FLIGHTS = LOAD '$flights_file' USING org.apache.pig.piggybank.storage.CSVExcelStorage(',', 'NO_MULTILINE', 'UNIX', 'SKIP_INPUT_HEADER')\n",
    "    AS (dayofmonth:int, dayofweek:int, carrier:chararray, flightnum:int, depdelay:int, arrdelay:int);\n",
    "\n",
    "-- Filtrar los vuelos que tienen un retraso mayor a 15 minutos\n",
    "delayed_flights = FILTER FLIGHTS BY arrdelay > 15;\n",
    "\n",
    "-- Agrupar los vuelos retrasados por aerolínea\n",
    "grouped_flights = GROUP delayed_flights BY carrier;\n",
    "\n",
    "-- Contar los vuelos retrasados por aerolínea\n",
    "counted_flights = FOREACH grouped_flights GENERATE group AS carrier, COUNT(delayed_flights) AS delayed_flights;\n",
    "\n",
    "-- Ordenar las aerolíneas por la cantidad de vuelos retrasados de mayor a menor\n",
    "sorted_flights = ORDER counted_flights BY delayed_flights DESC;\n",
    "\n",
    "-- Limitar los resultados a las cinco principales aerolíneas\n",
    "top_five_carriers = LIMIT sorted_flights 5;\n",
    "\n",
    "-- Almacenar o mostrar los resultados\n",
    "DUMP top_five_carriers;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-18 16:23:03,912 INFO pig.ExecTypeProvider: Trying ExecType : LOCAL\n",
      "2024-02-18 16:23:03,912 INFO pig.ExecTypeProvider: Picked LOCAL as the ExecType\n",
      "2024-02-18 16:23:03,958 [main] INFO  org.apache.pig.Main - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58\n",
      "2024-02-18 16:23:03,958 [main] INFO  org.apache.pig.Main - Logging error messages to: /media/notebooks/Tarea 3/notebooks/pig_1708269783955.log\n",
      "2024-02-18 16:23:03,976 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - user.name is deprecated. Instead, use mapreduce.job.user.name\n",
      "2024-02-18 16:23:04,114 [main] INFO  org.apache.pig.impl.util.Utils - Default bootup file /root/.pigbootup not found\n",
      "2024-02-18 16:23:04,156 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-02-18 16:23:04,157 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine - Connecting to hadoop file system at: file:///\n",
      "2024-02-18 16:23:04,172 [main] INFO  org.apache.pig.PigServer - Pig Script ID for the session: PIG-ejercicio2.pig-b6a5027b-d57e-4dda-9b8b-3f08d955c2f2\n",
      "2024-02-18 16:23:04,172 [main] WARN  org.apache.pig.PigServer - ATS is disabled since yarn.timeline-service.enabled set to false\n",
      "2024-02-18 16:23:04,627 [main] INFO  org.apache.pig.tools.pigstats.ScriptState - Pig features used in the script: GROUP_BY,ORDER_BY,FILTER,LIMIT\n",
      "2024-02-18 16:23:04,688 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}\n",
      "2024-02-18 16:23:04,792 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-18 16:23:04,842 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler - File concatenation threshold: 100 optimistic? false\n",
      "2024-02-18 16:23:04,877 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil - Choosing to move algebraic foreach to combiner\n",
      "2024-02-18 16:23:04,888 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR - Using Secondary Key Optimization for MapReduce node scope-40\n",
      "2024-02-18 16:23:04,894 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size before optimization: 4\n",
      "2024-02-18 16:23:04,894 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size after optimization: 4\n",
      "2024-02-18 16:23:05,088 [main] INFO  org.apache.hadoop.metrics2.impl.MetricsConfig - Loaded properties from hadoop-metrics2.properties\n",
      "2024-02-18 16:23:05,190 [main] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).\n",
      "2024-02-18 16:23:05,191 [main] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started\n",
      "2024-02-18 16:23:05,219 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2024-02-18 16:23:05,230 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-02-18 16:23:05,231 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2024-02-18 16:23:05,233 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2024-02-18 16:23:05,235 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2024-02-18 16:23:05,235 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Using reducer estimator: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator\n",
      "2024-02-18 16:23:05,239 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator - BytesPerReducer=1000000000 maxReducers=999 totalInputFileSize=72088113\n",
      "2024-02-18 16:23:05,239 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2024-02-18 16:23:05,239 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-02-18 16:23:05,245 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2024-02-18 16:23:05,254 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Key [pig.schematuple] is false, will not generate code.\n",
      "2024-02-18 16:23:05,254 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Starting process to move generated code to distributed cacche\n",
      "2024-02-18 16:23:05,254 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Distributed cache not supported or needed in local mode. Setting key [pig.schematuple.local.dir] with code temp directory: /tmp/1708269785254-0\n",
      "2024-02-18 16:23:05,324 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2024-02-18 16:23:05,340 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:23:05,354 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2024-02-18 16:23:05,401 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2024-02-18 16:23:05,409 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-18 16:23:05,410 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-02-18 16:23:05,418 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 3\n",
      "2024-02-18 16:23:05,449 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:3\n",
      "2024-02-18 16:23:05,575 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1221214718_0001\n",
      "2024-02-18 16:23:05,576 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2024-02-18 16:23:05,687 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2024-02-18 16:23:05,688 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2024-02-18 16:23:05,704 [Thread-6] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-02-18 16:23:05,704 [Thread-6] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-02-18 16:23:05,704 [Thread-6] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-02-18 16:23:05,706 [Thread-6] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:23:05,707 [Thread-6] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:23:05,709 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-18 16:23:05,732 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2024-02-18 16:23:05,735 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1221214718_0001_m_000000_0\n",
      "2024-02-18 16:23:05,776 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:23:05,776 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:23:05,800 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-18 16:23:05,804 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 33554432\n",
      "Input split[0]:\n",
      "   Length = 33554432\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-18 16:23:05,815 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/media/notebooks/Tarea 3/notebooks/flights.csv:0+33554432\n",
      "2024-02-18 16:23:05,831 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local1221214718_0001\n",
      "2024-02-18 16:23:05,831 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases FLIGHTS,counted_flights,delayed_flights,grouped_flights\n",
      "2024-02-18 16:23:05,831 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: FLIGHTS[4,10],FLIGHTS[-1,-1],delayed_flights[8,18],counted_flights[14,18],grouped_flights[11,18] C: counted_flights[14,18],grouped_flights[11,18] R: counted_flights[14,18]\n",
      "2024-02-18 16:23:05,833 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 0% complete\n",
      "2024-02-18 16:23:05,833 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local1221214718_0001]\n",
      "2024-02-18 16:23:05,884 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-18 16:23:05,886 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-18 16:23:05,886 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-18 16:23:05,886 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-18 16:23:05,886 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-18 16:23:05,889 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-18 16:23:05,899 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-18 16:23:05,901 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.data.SchemaTupleBackend - Key [pig.schematuple] was not set... will not generate code.\n",
      "2024-02-18 16:23:05,913 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: FLIGHTS[4,10],FLIGHTS[-1,-1],delayed_flights[8,18],counted_flights[14,18],grouped_flights[11,18] C: counted_flights[14,18],grouped_flights[11,18] R: counted_flights[14,18]\n",
      "2024-02-18 16:23:08,783 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-18 16:23:08,783 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-18 16:23:08,783 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-18 16:23:08,783 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 2639030; bufvoid = 104857600\n",
      "2024-02-18 16:23:08,783 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 25158788(100635152); length = 1055609/6553600\n",
      "2024-02-18 16:23:08,867 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigCombiner$Combine - Aliases being processed per job phase (AliasName[line,offset]): M: FLIGHTS[4,10],FLIGHTS[-1,-1],delayed_flights[8,18],counted_flights[14,18],grouped_flights[11,18] C: counted_flights[14,18],grouped_flights[11,18] R: counted_flights[14,18]\n",
      "2024-02-18 16:23:09,016 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-18 16:23:09,025 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1221214718_0001_m_000000_0 is done. And is in the process of committing\n",
      "2024-02-18 16:23:09,027 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-18 16:23:09,028 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1221214718_0001_m_000000_0' done.\n",
      "2024-02-18 16:23:09,032 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1221214718_0001_m_000000_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=33559765\n",
      "\t\tFILE: Number of bytes written=631053\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1257485\n",
      "\t\tMap output records=263903\n",
      "\t\tMap output bytes=2639030\n",
      "\t\tMap output materialized bytes=232\n",
      "\t\tInput split bytes=378\n",
      "\t\tCombine input records=263903\n",
      "\t\tCombine output records=16\n",
      "\t\tSpilled Records=16\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=384\n",
      "\t\tTotal committed heap usage (bytes)=729284608\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-18 16:23:09,033 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1221214718_0001_m_000000_0\n",
      "2024-02-18 16:23:09,033 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1221214718_0001_m_000001_0\n",
      "2024-02-18 16:23:09,037 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:23:09,037 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:23:09,037 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-18 16:23:09,039 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 33554432\n",
      "Input split[0]:\n",
      "   Length = 33554432\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-18 16:23:09,041 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/media/notebooks/Tarea 3/notebooks/flights.csv:33554432+33554432\n",
      "2024-02-18 16:23:09,048 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-18 16:23:09,049 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-18 16:23:09,049 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-18 16:23:09,049 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-18 16:23:09,049 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-18 16:23:09,050 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-18 16:23:09,054 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-18 16:23:09,055 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-18 16:23:09,066 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: FLIGHTS[4,10],FLIGHTS[-1,-1],delayed_flights[8,18],counted_flights[14,18],grouped_flights[11,18] C: counted_flights[14,18],grouped_flights[11,18] R: counted_flights[14,18]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-18 16:23:09,564 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 12% complete\n",
      "2024-02-18 16:23:09,584 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local1221214718_0001]\n",
      "2024-02-18 16:23:11,234 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-18 16:23:11,237 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-18 16:23:11,237 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-18 16:23:11,237 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 2360410; bufvoid = 104857600\n",
      "2024-02-18 16:23:11,237 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 25270236(101080944); length = 944161/6553600\n",
      "2024-02-18 16:23:11,319 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-18 16:23:11,324 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1221214718_0001_m_000001_0 is done. And is in the process of committing\n",
      "2024-02-18 16:23:11,329 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-18 16:23:11,329 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1221214718_0001_m_000001_0' done.\n",
      "2024-02-18 16:23:11,330 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1221214718_0001_m_000001_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=67119454\n",
      "\t\tFILE: Number of bytes written=631317\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1258869\n",
      "\t\tMap output records=236041\n",
      "\t\tMap output bytes=2360410\n",
      "\t\tMap output materialized bytes=232\n",
      "\t\tInput split bytes=378\n",
      "\t\tCombine input records=236041\n",
      "\t\tCombine output records=16\n",
      "\t\tSpilled Records=16\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=357\n",
      "\t\tTotal committed heap usage (bytes)=780140544\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-18 16:23:11,330 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1221214718_0001_m_000001_0\n",
      "2024-02-18 16:23:11,330 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1221214718_0001_m_000002_0\n",
      "2024-02-18 16:23:11,338 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:23:11,339 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:23:11,339 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-18 16:23:11,340 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 4979249\n",
      "Input split[0]:\n",
      "   Length = 4979249\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-18 16:23:11,342 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/media/notebooks/Tarea 3/notebooks/flights.csv:67108864+4979249\n",
      "2024-02-18 16:23:11,348 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-18 16:23:11,349 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-18 16:23:11,349 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-18 16:23:11,349 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-18 16:23:11,349 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-18 16:23:11,352 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-18 16:23:11,355 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-18 16:23:11,355 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-18 16:23:11,359 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: FLIGHTS[4,10],FLIGHTS[-1,-1],delayed_flights[8,18],counted_flights[14,18],grouped_flights[11,18] C: counted_flights[14,18],grouped_flights[11,18] R: counted_flights[14,18]\n",
      "2024-02-18 16:23:11,660 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-18 16:23:11,660 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-18 16:23:11,660 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-18 16:23:11,660 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 232760; bufvoid = 104857600\n",
      "2024-02-18 16:23:11,660 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26121296(104485184); length = 93101/6553600\n",
      "2024-02-18 16:23:11,673 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-18 16:23:11,676 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1221214718_0001_m_000002_0 is done. And is in the process of committing\n",
      "2024-02-18 16:23:11,679 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-18 16:23:11,679 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1221214718_0001_m_000002_0' done.\n",
      "2024-02-18 16:23:11,679 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1221214718_0001_m_000002_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72099352\n",
      "\t\tFILE: Number of bytes written=631522\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=185864\n",
      "\t\tMap output records=23276\n",
      "\t\tMap output bytes=232760\n",
      "\t\tMap output materialized bytes=173\n",
      "\t\tInput split bytes=378\n",
      "\t\tCombine input records=23276\n",
      "\t\tCombine output records=12\n",
      "\t\tSpilled Records=12\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=43\n",
      "\t\tTotal committed heap usage (bytes)=865599488\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-18 16:23:11,679 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1221214718_0001_m_000002_0\n",
      "2024-02-18 16:23:11,679 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2024-02-18 16:23:11,682 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2024-02-18 16:23:11,683 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1221214718_0001_r_000000_0\n",
      "2024-02-18 16:23:11,693 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:23:11,694 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:23:11,695 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-18 16:23:11,697 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@74341f9\n",
      "2024-02-18 16:23:11,698 [pool-4-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-18 16:23:11,714 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-02-18 16:23:11,716 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1221214718_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-02-18 16:23:11,742 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1221214718_0001_m_000001_0 decomp: 228 len: 232 to MEMORY\n",
      "2024-02-18 16:23:11,760 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 228 bytes from map-output for attempt_local1221214718_0001_m_000001_0\n",
      "2024-02-18 16:23:11,768 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 228, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->228\n",
      "2024-02-18 16:23:11,794 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1221214718_0001_m_000002_0 decomp: 169 len: 173 to MEMORY\n",
      "2024-02-18 16:23:11,796 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 169 bytes from map-output for attempt_local1221214718_0001_m_000002_0\n",
      "2024-02-18 16:23:11,796 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 169, inMemoryMapOutputs.size() -> 2, commitMemory -> 228, usedMemory ->397\n",
      "2024-02-18 16:23:11,797 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1221214718_0001_m_000000_0 decomp: 228 len: 232 to MEMORY\n",
      "2024-02-18 16:23:11,799 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 228 bytes from map-output for attempt_local1221214718_0001_m_000000_0\n",
      "2024-02-18 16:23:11,799 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 228, inMemoryMapOutputs.size() -> 3, commitMemory -> 397, usedMemory ->625\n",
      "2024-02-18 16:23:11,803 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2024-02-18 16:23:11,815 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.\n",
      "2024-02-18 16:23:11,816 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-02-18 16:23:11,833 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 3 sorted segments\n",
      "2024-02-18 16:23:11,836 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 3 segments left of total size: 604 bytes\n",
      "2024-02-18 16:23:11,846 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 3 segments, 625 bytes to disk to satisfy reduce memory limit\n",
      "2024-02-18 16:23:11,846 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 625 bytes from disk\n",
      "2024-02-18 16:23:11,847 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-02-18 16:23:11,847 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-18 16:23:11,848 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 614 bytes\n",
      "2024-02-18 16:23:11,848 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.\n",
      "2024-02-18 16:23:11,859 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:23:11,859 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:23:11,863 [pool-4-thread-1] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "2024-02-18 16:23:11,863 [pool-4-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-18 16:23:11,864 [pool-4-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-18 16:23:11,865 [pool-4-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: FLIGHTS[4,10],FLIGHTS[-1,-1],delayed_flights[8,18],counted_flights[14,18],grouped_flights[11,18] C: counted_flights[14,18],grouped_flights[11,18] R: counted_flights[14,18]\n",
      "2024-02-18 16:23:11,871 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1221214718_0001_r_000000_0 is done. And is in the process of committing\n",
      "2024-02-18 16:23:11,880 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.\n",
      "2024-02-18 16:23:11,880 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1221214718_0001_r_000000_0 is allowed to commit now\n",
      "2024-02-18 16:23:11,883 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1221214718_0001_r_000000_0' to file:/tmp/temp802090984/tmp-1011244137\n",
      "2024-02-18 16:23:11,888 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2024-02-18 16:23:11,888 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1221214718_0001_r_000000_0' done.\n",
      "2024-02-18 16:23:11,888 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1221214718_0001_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72100710\n",
      "\t\tFILE: Number of bytes written=632361\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=16\n",
      "\t\tReduce shuffle bytes=637\n",
      "\t\tReduce input records=44\n",
      "\t\tReduce output records=16\n",
      "\t\tSpilled Records=44\n",
      "\t\tShuffled Maps =3\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=3\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=865599488\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2024-02-18 16:23:11,888 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1221214718_0001_r_000000_0\n",
      "2024-02-18 16:23:11,896 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2024-02-18 16:23:12,089 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 25% complete\n",
      "2024-02-18 16:23:12,093 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:23:12,104 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:23:12,105 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "2024-02-18 16:23:12,106 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:23:12,179 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2024-02-18 16:23:12,180 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2024-02-18 16:23:12,207 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2024-02-18 16:23:12,207 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Using reducer estimator: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator\n",
      "2024-02-18 16:23:12,209 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator - BytesPerReducer=1000000000 maxReducers=999 totalInputFileSize=202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-18 16:23:12,218 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2024-02-18 16:23:12,220 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2024-02-18 16:23:12,260 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2024-02-18 16:23:12,300 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:23:12,306 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2024-02-18 16:23:12,313 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-18 16:23:12,313 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-02-18 16:23:12,314 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2024-02-18 16:23:12,336 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2024-02-18 16:23:12,344 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1153469595_0002\n",
      "2024-02-18 16:23:12,344 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2024-02-18 16:23:12,416 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2024-02-18 16:23:12,421 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2024-02-18 16:23:12,425 [Thread-17] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-02-18 16:23:12,426 [Thread-17] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-02-18 16:23:12,426 [Thread-17] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-02-18 16:23:12,427 [Thread-17] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:23:12,427 [Thread-17] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:23:12,428 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2024-02-18 16:23:12,450 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2024-02-18 16:23:12,450 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1153469595_0002_m_000000_0\n",
      "2024-02-18 16:23:12,455 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:23:12,456 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:23:12,456 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-18 16:23:12,457 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 202\n",
      "Input split[0]:\n",
      "   Length = 202\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-18 16:23:12,479 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp802090984/tmp-1011244137/part-r-00000:0+202\n",
      "2024-02-18 16:23:12,486 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-18 16:23:12,486 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-18 16:23:12,486 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-18 16:23:12,486 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-18 16:23:12,487 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-18 16:23:12,508 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-18 16:23:12,515 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-18 16:23:12,515 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-18 16:23:12,516 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: sorted_flights[17,17] C:  R: \n",
      "2024-02-18 16:23:12,523 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-18 16:23:12,524 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-18 16:23:12,524 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-18 16:23:12,524 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 308; bufvoid = 104857600\n",
      "2024-02-18 16:23:12,524 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214336(104857344); length = 61/6553600\n",
      "2024-02-18 16:23:12,538 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-18 16:23:12,553 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1153469595_0002_m_000000_0 is done. And is in the process of committing\n",
      "2024-02-18 16:23:12,578 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-18 16:23:12,578 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1153469595_0002_m_000000_0' done.\n",
      "2024-02-18 16:23:12,579 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1153469595_0002_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72101361\n",
      "\t\tFILE: Number of bytes written=1246689\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=16\n",
      "\t\tMap output records=16\n",
      "\t\tMap output bytes=308\n",
      "\t\tMap output materialized bytes=346\n",
      "\t\tInput split bytes=378\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=16\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=865599488\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-18 16:23:12,579 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1153469595_0002_m_000000_0\n",
      "2024-02-18 16:23:12,581 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2024-02-18 16:23:12,583 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2024-02-18 16:23:12,584 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1153469595_0002_r_000000_0\n",
      "2024-02-18 16:23:12,591 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:23:12,591 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:23:12,592 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-18 16:23:12,592 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6bce55a6\n",
      "2024-02-18 16:23:12,592 [pool-9-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:23:12,593 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-18 16:23:12,604 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1153469595_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-02-18 16:23:12,635 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1153469595_0002_m_000000_0 decomp: 342 len: 346 to MEMORY\n",
      "2024-02-18 16:23:12,668 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 342 bytes from map-output for attempt_local1153469595_0002_m_000000_0\n",
      "2024-02-18 16:23:12,681 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 342, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->342\n",
      "2024-02-18 16:23:12,685 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2024-02-18 16:23:12,699 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-18 16:23:12,700 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-02-18 16:23:12,701 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-18 16:23:12,719 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 326 bytes\n",
      "2024-02-18 16:23:12,737 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 342 bytes to disk to satisfy reduce memory limit\n",
      "2024-02-18 16:23:12,737 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 346 bytes from disk\n",
      "2024-02-18 16:23:12,738 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-02-18 16:23:12,738 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-18 16:23:12,738 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 326 bytes\n",
      "2024-02-18 16:23:12,738 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-18 16:23:12,740 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:23:12,741 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:23:12,742 [pool-9-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-18 16:23:12,742 [pool-9-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-18 16:23:12,744 [pool-9-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: sorted_flights[17,17] C:  R: \n",
      "2024-02-18 16:23:12,750 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1153469595_0002_r_000000_0 is done. And is in the process of committing\n",
      "2024-02-18 16:23:12,752 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-18 16:23:12,752 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1153469595_0002_r_000000_0 is allowed to commit now\n",
      "2024-02-18 16:23:12,756 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1153469595_0002_r_000000_0' to file:/tmp/temp802090984/tmp140130490\n",
      "2024-02-18 16:23:12,760 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2024-02-18 16:23:12,760 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1153469595_0002_r_000000_0' done.\n",
      "2024-02-18 16:23:12,760 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1153469595_0002_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72102085\n",
      "\t\tFILE: Number of bytes written=1247098\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce shuffle bytes=346\n",
      "\t\tReduce input records=16\n",
      "\t\tReduce output records=1\n",
      "\t\tSpilled Records=16\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=865599488\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2024-02-18 16:23:12,760 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1153469595_0002_r_000000_0\n",
      "2024-02-18 16:23:12,760 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2024-02-18 16:23:12,774 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local1153469595_0002\n",
      "2024-02-18 16:23:12,774 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases sorted_flights\n",
      "2024-02-18 16:23:12,774 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: sorted_flights[17,17] C:  R: \n",
      "2024-02-18 16:23:12,776 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 50% complete\n",
      "2024-02-18 16:23:12,776 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local1153469595_0002]\n",
      "2024-02-18 16:23:12,940 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:23:12,943 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:23:12,943 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:23:12,966 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2024-02-18 16:23:12,966 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2024-02-18 16:23:12,967 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2024-02-18 16:23:12,967 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2024-02-18 16:23:12,968 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2024-02-18 16:23:12,983 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2024-02-18 16:23:12,985 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:23:12,991 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2024-02-18 16:23:12,993 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-18 16:23:12,993 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-02-18 16:23:12,993 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2024-02-18 16:23:12,999 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2024-02-18 16:23:13,022 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local2120282653_0003\n",
      "2024-02-18 16:23:13,025 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-18 16:23:13,079 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2024-02-18 16:23:13,096 [Thread-24] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2024-02-18 16:23:13,109 [Thread-24] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-02-18 16:23:13,109 [Thread-24] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-02-18 16:23:13,109 [Thread-24] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-02-18 16:23:13,109 [Thread-24] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:23:13,109 [Thread-24] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:23:13,109 [Thread-24] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2024-02-18 16:23:13,136 [Thread-24] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2024-02-18 16:23:13,136 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local2120282653_0003_m_000000_0\n",
      "2024-02-18 16:23:13,143 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:23:13,143 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:23:13,143 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-18 16:23:13,144 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 202\n",
      "Input split[0]:\n",
      "   Length = 202\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-18 16:23:13,145 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp802090984/tmp-1011244137/part-r-00000:0+202\n",
      "2024-02-18 16:23:13,167 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-18 16:23:13,167 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-18 16:23:13,167 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-18 16:23:13,167 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-18 16:23:13,167 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-18 16:23:13,174 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-18 16:23:13,196 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-18 16:23:13,197 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-18 16:23:13,232 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: sorted_flights[17,17] C:  R: \n",
      "2024-02-18 16:23:13,233 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-18 16:23:13,234 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-18 16:23:13,234 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-18 16:23:13,234 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 288; bufvoid = 104857600\n",
      "2024-02-18 16:23:13,234 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214336(104857344); length = 61/6553600\n",
      "2024-02-18 16:23:13,238 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-18 16:23:13,276 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local2120282653_0003_m_000000_0 is done. And is in the process of committing\n",
      "2024-02-18 16:23:13,288 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-18 16:23:13,288 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local2120282653_0003_m_000000_0' done.\n",
      "2024-02-18 16:23:13,288 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local2120282653_0003_m_000000_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72102736\n",
      "\t\tFILE: Number of bytes written=1867809\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=16\n",
      "\t\tMap output records=16\n",
      "\t\tMap output bytes=288\n",
      "\t\tMap output materialized bytes=106\n",
      "\t\tInput split bytes=378\n",
      "\t\tCombine input records=16\n",
      "\t\tCombine output records=5\n",
      "\t\tSpilled Records=5\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=9\n",
      "\t\tTotal committed heap usage (bytes)=866123776\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-18 16:23:13,288 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local2120282653_0003_m_000000_0\n",
      "2024-02-18 16:23:13,289 [Thread-24] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2024-02-18 16:23:13,291 [Thread-24] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2024-02-18 16:23:13,291 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local2120282653_0003_r_000000_0\n",
      "2024-02-18 16:23:13,295 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:23:13,296 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:23:13,300 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-18 16:23:13,300 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5a77af43\n",
      "2024-02-18 16:23:13,300 [pool-12-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:23:13,303 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-02-18 16:23:13,316 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local2120282653_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-02-18 16:23:13,323 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#3 about to shuffle output of map attempt_local2120282653_0003_m_000000_0 decomp: 102 len: 106 to MEMORY\n",
      "2024-02-18 16:23:13,327 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 102 bytes from map-output for attempt_local2120282653_0003_m_000000_0\n",
      "2024-02-18 16:23:13,327 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 102, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-18 16:23:13,344 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2024-02-18 16:23:13,368 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-18 16:23:13,369 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-02-18 16:23:13,378 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-18 16:23:13,380 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 90 bytes\n",
      "2024-02-18 16:23:13,381 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 102 bytes to disk to satisfy reduce memory limit\n",
      "2024-02-18 16:23:13,382 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 106 bytes from disk\n",
      "2024-02-18 16:23:13,382 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-02-18 16:23:13,383 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-18 16:23:13,384 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 90 bytes\n",
      "2024-02-18 16:23:13,385 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-18 16:23:13,387 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:23:13,387 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:23:13,389 [pool-12-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-18 16:23:13,389 [pool-12-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-18 16:23:13,390 [pool-12-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: sorted_flights[17,17] C:  R: \n",
      "2024-02-18 16:23:13,390 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local2120282653_0003_r_000000_0 is done. And is in the process of committing\n",
      "2024-02-18 16:23:13,392 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-18 16:23:13,392 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local2120282653_0003_r_000000_0 is allowed to commit now\n",
      "2024-02-18 16:23:13,393 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local2120282653_0003_r_000000_0' to file:/tmp/temp802090984/tmp1039768484\n",
      "2024-02-18 16:23:13,406 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2024-02-18 16:23:13,406 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local2120282653_0003_r_000000_0' done.\n",
      "2024-02-18 16:23:13,406 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local2120282653_0003_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72102980\n",
      "\t\tFILE: Number of bytes written=1867997\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=5\n",
      "\t\tReduce shuffle bytes=106\n",
      "\t\tReduce input records=5\n",
      "\t\tReduce output records=5\n",
      "\t\tSpilled Records=5\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=866123776\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2024-02-18 16:23:13,406 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local2120282653_0003_r_000000_0\n",
      "2024-02-18 16:23:13,406 [Thread-24] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2024-02-18 16:23:13,487 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local2120282653_0003\n",
      "2024-02-18 16:23:13,488 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases sorted_flights\n",
      "2024-02-18 16:23:13,488 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: sorted_flights[17,17] C:  R: \n",
      "2024-02-18 16:23:13,495 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 75% complete\n",
      "2024-02-18 16:23:13,495 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local2120282653_0003]\n",
      "2024-02-18 16:23:13,613 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:23:13,616 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:23:13,616 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:23:13,623 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2024-02-18 16:23:13,624 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2024-02-18 16:23:13,624 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2024-02-18 16:23:13,625 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2024-02-18 16:23:13,626 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2024-02-18 16:23:13,632 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2024-02-18 16:23:13,636 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:23:13,639 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2024-02-18 16:23:13,640 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-18 16:23:13,640 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-02-18 16:23:13,640 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2024-02-18 16:23:13,642 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2024-02-18 16:23:13,649 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1903844562_0004\n",
      "2024-02-18 16:23:13,650 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2024-02-18 16:23:13,704 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2024-02-18 16:23:13,712 [Thread-31] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2024-02-18 16:23:13,726 [Thread-31] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-02-18 16:23:13,726 [Thread-31] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-02-18 16:23:13,726 [Thread-31] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-02-18 16:23:13,728 [Thread-31] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:23:13,728 [Thread-31] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:23:13,728 [Thread-31] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2024-02-18 16:23:13,743 [Thread-31] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2024-02-18 16:23:13,744 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1903844562_0004_m_000000_0\n",
      "2024-02-18 16:23:13,750 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:23:13,750 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:23:13,750 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-18 16:23:13,751 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 70\n",
      "Input split[0]:\n",
      "   Length = 70\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-18 16:23:13,752 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp802090984/tmp1039768484/part-r-00000:0+70\n",
      "2024-02-18 16:23:13,757 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-18 16:23:13,757 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-18 16:23:13,757 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-18 16:23:13,757 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-18 16:23:13,757 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-18 16:23:13,759 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-18 16:23:13,760 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-18 16:23:13,760 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-18 16:23:13,761 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: sorted_flights[17,17] C:  R: \n",
      "2024-02-18 16:23:13,761 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-18 16:23:13,762 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-18 16:23:13,762 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-18 16:23:13,762 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 90; bufvoid = 104857600\n",
      "2024-02-18 16:23:13,762 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214380(104857520); length = 17/6553600\n",
      "2024-02-18 16:23:13,764 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-18 16:23:13,768 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1903844562_0004_m_000000_0 is done. And is in the process of committing\n",
      "2024-02-18 16:23:13,772 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-18 16:23:13,772 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1903844562_0004_m_000000_0' done.\n",
      "2024-02-18 16:23:13,772 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1903844562_0004_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72103497\n",
      "\t\tFILE: Number of bytes written=2476193\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=5\n",
      "\t\tMap output records=5\n",
      "\t\tMap output bytes=90\n",
      "\t\tMap output materialized bytes=106\n",
      "\t\tInput split bytes=377\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=5\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=866123776\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-18 16:23:13,772 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1903844562_0004_m_000000_0\n",
      "2024-02-18 16:23:13,773 [Thread-31] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2024-02-18 16:23:13,776 [Thread-31] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2024-02-18 16:23:13,776 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1903844562_0004_r_000000_0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-18 16:23:13,816 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:23:13,816 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:23:13,817 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-18 16:23:13,817 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@433ffce5\n",
      "2024-02-18 16:23:13,817 [pool-15-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:23:13,820 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-02-18 16:23:13,823 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1903844562_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-02-18 16:23:13,830 [localfetcher#4] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#4 about to shuffle output of map attempt_local1903844562_0004_m_000000_0 decomp: 102 len: 106 to MEMORY\n",
      "2024-02-18 16:23:13,830 [localfetcher#4] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 102 bytes from map-output for attempt_local1903844562_0004_m_000000_0\n",
      "2024-02-18 16:23:13,830 [localfetcher#4] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 102, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->102\n",
      "2024-02-18 16:23:13,834 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2024-02-18 16:23:13,843 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-18 16:23:13,843 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-02-18 16:23:13,845 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-18 16:23:13,852 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 90 bytes\n",
      "2024-02-18 16:23:13,853 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 102 bytes to disk to satisfy reduce memory limit\n",
      "2024-02-18 16:23:13,856 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 106 bytes from disk\n",
      "2024-02-18 16:23:13,856 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-02-18 16:23:13,856 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-18 16:23:13,857 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 90 bytes\n",
      "2024-02-18 16:23:13,858 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-18 16:23:13,860 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:23:13,860 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:23:13,862 [pool-15-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-18 16:23:13,862 [pool-15-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-18 16:23:13,864 [pool-15-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: sorted_flights[17,17] C:  R: \n",
      "2024-02-18 16:23:13,865 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1903844562_0004_r_000000_0 is done. And is in the process of committing\n",
      "2024-02-18 16:23:13,868 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-18 16:23:13,869 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1903844562_0004_r_000000_0 is allowed to commit now\n",
      "2024-02-18 16:23:13,875 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1903844562_0004_r_000000_0' to file:/tmp/temp802090984/tmp774786063\n",
      "2024-02-18 16:23:13,890 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2024-02-18 16:23:13,890 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1903844562_0004_r_000000_0' done.\n",
      "2024-02-18 16:23:13,890 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1903844562_0004_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72103741\n",
      "\t\tFILE: Number of bytes written=2476381\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=5\n",
      "\t\tReduce shuffle bytes=106\n",
      "\t\tReduce input records=5\n",
      "\t\tReduce output records=5\n",
      "\t\tSpilled Records=5\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=866123776\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2024-02-18 16:23:13,890 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1903844562_0004_r_000000_0\n",
      "2024-02-18 16:23:13,890 [Thread-31] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2024-02-18 16:23:14,014 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local1903844562_0004\n",
      "2024-02-18 16:23:14,014 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases sorted_flights\n",
      "2024-02-18 16:23:14,014 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: sorted_flights[17,17] C:  R: \n",
      "2024-02-18 16:23:14,016 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:23:14,019 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:23:14,020 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:23:14,029 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 100% complete\n",
      "2024-02-18 16:23:14,035 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats - Script Statistics: \n",
      "\n",
      "HadoopVersion\tPigVersion\tUserId\tStartedAt\tFinishedAt\tFeatures\n",
      "3.3.1\t0.17.0\troot\t2024-02-18 16:23:05\t2024-02-18 16:23:14\tGROUP_BY,ORDER_BY,FILTER,LIMIT\n",
      "\n",
      "Success!\n",
      "\n",
      "Job Stats (time in seconds):\n",
      "JobId\tMaps\tReduces\tMaxMapTime\tMinMapTime\tAvgMapTime\tMedianMapTime\tMaxReduceTime\tMinReduceTime\tAvgReduceTime\tMedianReducetime\tAlias\tFeature\tOutputs\n",
      "job_local1153469595_0002\t1\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tsorted_flights\tSAMPLER\t\n",
      "job_local1221214718_0001\t3\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tFLIGHTS,counted_flights,delayed_flights,grouped_flights\tGROUP_BY,COMBINER\t\n",
      "job_local1903844562_0004\t1\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tsorted_flights\t\tfile:/tmp/temp802090984/tmp774786063,\n",
      "job_local2120282653_0003\t1\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tsorted_flights\tORDER_BY,COMBINER\t\n",
      "\n",
      "Input(s):\n",
      "Successfully read 2702218 records from: \"file:///media/notebooks/Tarea 3/notebooks/flights.csv\"\n",
      "\n",
      "Output(s):\n",
      "Successfully stored 5 records in: \"file:/tmp/temp802090984/tmp774786063\"\n",
      "\n",
      "Counters:\n",
      "Total records written : 5\n",
      "Total bytes written : 0\n",
      "Spillable Memory Manager spill count : 0\n",
      "Total bags proactively spilled: 0\n",
      "Total records proactively spilled: 0\n",
      "\n",
      "Job DAG:\n",
      "job_local1221214718_0001\t->\tjob_local1153469595_0002,\n",
      "job_local1153469595_0002\t->\tjob_local2120282653_0003,\n",
      "job_local2120282653_0003\t->\tjob_local1903844562_0004,\n",
      "job_local1903844562_0004\n",
      "\n",
      "\n",
      "2024-02-18 16:23:14,035 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:23:14,036 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:23:14,037 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:23:14,040 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:23:14,041 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:23:14,042 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:23:14,044 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:23:14,044 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:23:14,045 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:23:14,048 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:23:14,049 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:23:14,049 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:23:14,051 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Success!\n",
      "2024-02-18 16:23:14,052 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-18 16:23:14,054 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-18 16:23:14,054 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(WN,142850)\r\n",
      "(AA,59007)\r\n",
      "(UA,58758)\r\n",
      "(DL,53687)\r\n",
      "(EV,36161)\r\n",
      "2024-02-18 16:23:14,078 [main] INFO  org.apache.pig.Main - Pig script completed in 10 seconds and 287 milliseconds (10287 ms)\r\n"
     ]
    }
   ],
   "source": [
    "! pig -x local -f ejercicio2.pig -param flights_file='flights.csv' -param output_dir='pig/output/flights'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.- Resuelve el ejercicio 3 con Pig Latin\n",
    "\n",
    "Se espera el siguiente resultado:\n",
    "\n",
    "![solución 5](./img/5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ejercicio3.pig\n"
     ]
    }
   ],
   "source": [
    "%%writefile ejercicio3.pig\n",
    "\n",
    "REGISTER piggybank.jar\n",
    "\n",
    "-- Leemos el fichero fligths.csv\n",
    "\n",
    "FLIGHTS = LOAD '$flights_file' USING\n",
    "       org.apache.pig.piggybank.storage.CSVExcelStorage(',', 'NO_MULTILINE', 'UNIX', 'SKIP_INPUT_HEADER')\n",
    "       AS (dayofmonth:int, dayofweek:int, carrier:chararray, \n",
    "               depairportid:chararray, arrairportid:chararray, depdelay:int, arrdelay:int);\n",
    "\n",
    "-- Filtramos los vuelos que salieron con retraso\n",
    "DELAYED_FLIGHTS = FILTER FLIGHTS BY depdelay > 15;\n",
    "\n",
    "-- Filtramos los vuelos que salieron con retraso pero que llegaron con 15 minutos o menos de retraso\n",
    "RECOVERED_FLIGHTS = FILTER FLIGHTS BY depdelay > 15 AND arrdelay <= 15;\n",
    "\n",
    "-- Agrupamos los vuelos retrasados por aerolínea\n",
    "GROUPED_DELAYED = GROUP DELAYED_FLIGHTS BY carrier;\n",
    "GROUPED_RECOVERED = GROUP RECOVERED_FLIGHTS BY carrier;\n",
    "-- Contamos los vuelos retrasados y los vuelos recuperados por aerolínea\n",
    "COUNT_DELAYED = FOREACH GROUPED_DELAYED GENERATE group AS carrier, COUNT(DELAYED_FLIGHTS) AS total_delayed;\n",
    "COUNT_RECOVERED = FOREACH GROUPED_RECOVERED GENERATE group AS carrier, COUNT(RECOVERED_FLIGHTS) AS total_recovered;\n",
    "\n",
    "-- Realizamos un JOIN por aerolínea para tener ambos conteos en la misma tupla\n",
    "JOINED = JOIN COUNT_DELAYED BY carrier, COUNT_RECOVERED BY carrier;\n",
    "\n",
    "-- Calculamos el porcentaje de recuperación\n",
    "CALCULATED_PERCENTAGE = FOREACH JOINED GENERATE\n",
    "    COUNT_DELAYED::carrier AS carrier,\n",
    "    ((float)COUNT_RECOVERED::total_recovered / (float)COUNT_DELAYED::total_delayed) AS percent_recovered;\n",
    "\n",
    "-- Ordenamos las aerolíneas por el porcentaje de recuperación de mayor a menor\n",
    "ORDERED_RECOVERY = ORDER CALCULATED_PERCENTAGE BY percent_recovered DESC;\n",
    "\n",
    "-- Limitamos a las 5 aerolíneas principales\n",
    "TOP_5_RECOVERY = LIMIT ORDERED_RECOVERY 5;\n",
    "\n",
    "-- Mostramos el resultado\n",
    "DUMP TOP_5_RECOVERY;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-18 16:12:38,477 INFO pig.ExecTypeProvider: Trying ExecType : LOCAL\n",
      "2024-02-18 16:12:38,477 INFO pig.ExecTypeProvider: Picked LOCAL as the ExecType\n",
      "2024-02-18 16:12:38,510 [main] INFO  org.apache.pig.Main - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58\n",
      "2024-02-18 16:12:38,511 [main] INFO  org.apache.pig.Main - Logging error messages to: /media/notebooks/Tarea 3/notebooks/pig_1708269158509.log\n",
      "2024-02-18 16:12:38,521 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - user.name is deprecated. Instead, use mapreduce.job.user.name\n",
      "2024-02-18 16:12:38,629 [main] INFO  org.apache.pig.impl.util.Utils - Default bootup file /root/.pigbootup not found\n",
      "2024-02-18 16:12:38,676 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-02-18 16:12:38,679 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine - Connecting to hadoop file system at: file:///\n",
      "2024-02-18 16:12:38,696 [main] INFO  org.apache.pig.PigServer - Pig Script ID for the session: PIG-ejercicio3.pig-e5531393-53b1-4a42-a8e9-628600928750\n",
      "2024-02-18 16:12:38,696 [main] WARN  org.apache.pig.PigServer - ATS is disabled since yarn.timeline-service.enabled set to false\n",
      "2024-02-18 16:12:39,122 [main] INFO  org.apache.pig.tools.pigstats.ScriptState - Pig features used in the script: HASH_JOIN,GROUP_BY,ORDER_BY,FILTER,LIMIT\n",
      "2024-02-18 16:12:39,148 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}\n",
      "2024-02-18 16:12:39,206 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-18 16:12:39,258 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler - File concatenation threshold: 100 optimistic? false\n",
      "2024-02-18 16:12:39,277 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil - Choosing to move algebraic foreach to combiner\n",
      "2024-02-18 16:12:39,286 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil - Choosing to move algebraic foreach to combiner\n",
      "2024-02-18 16:12:39,299 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR - Using Secondary Key Optimization for MapReduce node scope-100\n",
      "2024-02-18 16:12:39,302 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler$LastInputStreamingOptimizer - Rewrite: POPackage->POForEach to POPackage(JoinPackager)\n",
      "2024-02-18 16:12:39,306 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size before optimization: 7\n",
      "2024-02-18 16:12:39,307 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - Merged MR job 87 into MR job 84\n",
      "2024-02-18 16:12:39,308 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - Merged MR job 92 into MR job 84\n",
      "2024-02-18 16:12:39,308 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - Requested parallelism of splitter: -1\n",
      "2024-02-18 16:12:39,308 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - Merged 2 map-reduce splittees.\n",
      "2024-02-18 16:12:39,308 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - Merged 2 out of total 3 MR operators.\n",
      "2024-02-18 16:12:39,308 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size after optimization: 5\n",
      "2024-02-18 16:12:39,454 [main] INFO  org.apache.hadoop.metrics2.impl.MetricsConfig - Loaded properties from hadoop-metrics2.properties\n",
      "2024-02-18 16:12:39,539 [main] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).\n",
      "2024-02-18 16:12:39,539 [main] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started\n",
      "2024-02-18 16:12:39,563 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2024-02-18 16:12:39,569 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-02-18 16:12:39,569 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2024-02-18 16:12:39,570 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2024-02-18 16:12:39,578 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2024-02-18 16:12:39,580 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Using reducer estimator: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator\n",
      "2024-02-18 16:12:39,588 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator - BytesPerReducer=1000000000 maxReducers=999 totalInputFileSize=72088113\n",
      "2024-02-18 16:12:39,589 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2024-02-18 16:12:39,589 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-02-18 16:12:39,599 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up multi store job\n",
      "2024-02-18 16:12:39,604 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Key [pig.schematuple] is false, will not generate code.\n",
      "2024-02-18 16:12:39,604 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Starting process to move generated code to distributed cacche\n",
      "2024-02-18 16:12:39,604 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Distributed cache not supported or needed in local mode. Setting key [pig.schematuple.local.dir] with code temp directory: /tmp/1708269159604-0\n",
      "2024-02-18 16:12:39,697 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2024-02-18 16:12:39,707 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:39,716 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2024-02-18 16:12:39,784 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2024-02-18 16:12:39,800 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-18 16:12:39,801 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-02-18 16:12:39,820 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 3\n",
      "2024-02-18 16:12:39,842 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:3\n",
      "2024-02-18 16:12:40,040 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1824884447_0001\n",
      "2024-02-18 16:12:40,041 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2024-02-18 16:12:40,120 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2024-02-18 16:12:40,122 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2024-02-18 16:12:40,138 [Thread-6] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-02-18 16:12:40,139 [Thread-6] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-02-18 16:12:40,139 [Thread-6] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-02-18 16:12:40,141 [Thread-6] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:12:40,141 [Thread-6] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:12:40,143 [Thread-6] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:12:40,143 [Thread-6] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:12:40,143 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-18 16:12:40,203 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2024-02-18 16:12:40,203 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local1824884447_0001\n",
      "2024-02-18 16:12:40,203 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases COUNT_DELAYED,COUNT_RECOVERED,DELAYED_FLIGHTS,FLIGHTS,GROUPED_DELAYED,GROUPED_RECOVERED,RECOVERED_FLIGHTS\n",
      "2024-02-18 16:12:40,203 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: FLIGHTS[6,10],FLIGHTS[-1,-1],DELAYED_FLIGHTS[12,18],COUNT_DELAYED[21,16],GROUPED_DELAYED[18,18],RECOVERED_FLIGHTS[15,20],COUNT_RECOVERED[22,18],GROUPED_RECOVERED[19,20] C: COUNT_DELAYED[21,16],GROUPED_DELAYED[18,18],COUNT_RECOVERED[22,18],GROUPED_RECOVERED[19,20] R: COUNT_DELAYED[21,16],COUNT_RECOVERED[22,18]\n",
      "2024-02-18 16:12:40,203 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1824884447_0001_m_000000_0\n",
      "2024-02-18 16:12:40,207 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 0% complete\n",
      "2024-02-18 16:12:40,207 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local1824884447_0001]\n",
      "2024-02-18 16:12:40,232 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:12:40,232 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:12:40,237 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:12:40,237 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:12:40,288 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-18 16:12:40,293 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 33554432\n",
      "Input split[0]:\n",
      "   Length = 33554432\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-18 16:12:40,306 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/media/notebooks/Tarea 3/notebooks/flights.csv:0+33554432\n",
      "2024-02-18 16:12:40,373 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-18 16:12:40,373 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-18 16:12:40,373 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-18 16:12:40,373 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-18 16:12:40,373 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-18 16:12:40,379 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-18 16:12:40,389 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-18 16:12:40,392 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.data.SchemaTupleBackend - Key [pig.schematuple] was not set... will not generate code.\n",
      "2024-02-18 16:12:40,403 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: FLIGHTS[6,10],FLIGHTS[-1,-1],DELAYED_FLIGHTS[12,18],COUNT_DELAYED[21,16],GROUPED_DELAYED[18,18],RECOVERED_FLIGHTS[15,20],COUNT_RECOVERED[22,18],GROUPED_RECOVERED[19,20] C: COUNT_DELAYED[21,16],GROUPED_DELAYED[18,18],COUNT_RECOVERED[22,18],GROUPED_RECOVERED[19,20] R: COUNT_DELAYED[21,16],COUNT_RECOVERED[22,18]\n",
      "2024-02-18 16:12:43,452 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-18 16:12:43,455 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-18 16:12:43,455 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-18 16:12:43,455 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 3119320; bufvoid = 104857600\n",
      "2024-02-18 16:12:43,455 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 24966672(99866688); length = 1247725/6553600\n",
      "2024-02-18 16:12:43,592 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigCombiner$Combine - Aliases being processed per job phase (AliasName[line,offset]): M: FLIGHTS[6,10],FLIGHTS[-1,-1],DELAYED_FLIGHTS[12,18],COUNT_DELAYED[21,16],GROUPED_DELAYED[18,18],RECOVERED_FLIGHTS[15,20],COUNT_RECOVERED[22,18],GROUPED_RECOVERED[19,20] C: COUNT_DELAYED[21,16],GROUPED_DELAYED[18,18],COUNT_RECOVERED[22,18],GROUPED_RECOVERED[19,20] R: COUNT_DELAYED[21,16],COUNT_RECOVERED[22,18]\n",
      "2024-02-18 16:12:43,785 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-18 16:12:43,797 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1824884447_0001_m_000000_0 is done. And is in the process of committing\n",
      "2024-02-18 16:12:43,800 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-18 16:12:43,801 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1824884447_0001_m_000000_0' done.\n",
      "2024-02-18 16:12:43,810 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1824884447_0001_m_000000_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=33559765\n",
      "\t\tFILE: Number of bytes written=642810\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1257485\n",
      "\t\tMap output records=311932\n",
      "\t\tMap output bytes=3119320\n",
      "\t\tMap output materialized bytes=455\n",
      "\t\tInput split bytes=378\n",
      "\t\tCombine input records=311932\n",
      "\t\tCombine output records=32\n",
      "\t\tSpilled Records=32\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=155\n",
      "\t\tTotal committed heap usage (bytes)=521666560\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-18 16:12:43,810 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1824884447_0001_m_000000_0\n",
      "2024-02-18 16:12:43,811 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1824884447_0001_m_000001_0\n",
      "2024-02-18 16:12:43,814 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:12:43,814 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:12:43,815 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:12:43,815 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:12:43,816 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-18 16:12:43,817 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 33554432\n",
      "Input split[0]:\n",
      "   Length = 33554432\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-18 16:12:43,819 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/media/notebooks/Tarea 3/notebooks/flights.csv:33554432+33554432\n",
      "2024-02-18 16:12:43,823 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-18 16:12:43,823 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-18 16:12:43,823 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-18 16:12:43,823 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-18 16:12:43,823 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-18 16:12:43,824 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-18 16:12:43,827 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 10% complete\n",
      "2024-02-18 16:12:43,829 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local1824884447_0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-18 16:12:43,836 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-18 16:12:43,836 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-18 16:12:43,843 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: FLIGHTS[6,10],FLIGHTS[-1,-1],DELAYED_FLIGHTS[12,18],COUNT_DELAYED[21,16],GROUPED_DELAYED[18,18],RECOVERED_FLIGHTS[15,20],COUNT_RECOVERED[22,18],GROUPED_RECOVERED[19,20] C: COUNT_DELAYED[21,16],GROUPED_DELAYED[18,18],COUNT_RECOVERED[22,18],GROUPED_RECOVERED[19,20] R: COUNT_DELAYED[21,16],COUNT_RECOVERED[22,18]\n",
      "2024-02-18 16:12:46,308 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-18 16:12:46,308 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-18 16:12:46,308 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-18 16:12:46,308 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 2854600; bufvoid = 104857600\n",
      "2024-02-18 16:12:46,308 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 25072560(100290240); length = 1141837/6553600\n",
      "2024-02-18 16:12:46,421 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-18 16:12:46,427 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1824884447_0001_m_000001_0 is done. And is in the process of committing\n",
      "2024-02-18 16:12:46,428 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-18 16:12:46,428 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1824884447_0001_m_000001_0' done.\n",
      "2024-02-18 16:12:46,429 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1824884447_0001_m_000001_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=67119454\n",
      "\t\tFILE: Number of bytes written=643297\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1258869\n",
      "\t\tMap output records=285460\n",
      "\t\tMap output bytes=2854600\n",
      "\t\tMap output materialized bytes=455\n",
      "\t\tInput split bytes=378\n",
      "\t\tCombine input records=285460\n",
      "\t\tCombine output records=32\n",
      "\t\tSpilled Records=32\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=183\n",
      "\t\tTotal committed heap usage (bytes)=660078592\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-18 16:12:46,429 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1824884447_0001_m_000001_0\n",
      "2024-02-18 16:12:46,429 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1824884447_0001_m_000002_0\n",
      "2024-02-18 16:12:46,432 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:12:46,432 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:12:46,433 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:12:46,433 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:12:46,434 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-18 16:12:46,436 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 4979249\n",
      "Input split[0]:\n",
      "   Length = 4979249\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-18 16:12:46,438 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/media/notebooks/Tarea 3/notebooks/flights.csv:67108864+4979249\n",
      "2024-02-18 16:12:46,442 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-18 16:12:46,442 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-18 16:12:46,443 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-18 16:12:46,443 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-18 16:12:46,443 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-18 16:12:46,443 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-18 16:12:46,447 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-18 16:12:46,447 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-18 16:12:46,456 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: FLIGHTS[6,10],FLIGHTS[-1,-1],DELAYED_FLIGHTS[12,18],COUNT_DELAYED[21,16],GROUPED_DELAYED[18,18],RECOVERED_FLIGHTS[15,20],COUNT_RECOVERED[22,18],GROUPED_RECOVERED[19,20] C: COUNT_DELAYED[21,16],GROUPED_DELAYED[18,18],COUNT_RECOVERED[22,18],GROUPED_RECOVERED[19,20] R: COUNT_DELAYED[21,16],COUNT_RECOVERED[22,18]\n",
      "2024-02-18 16:12:46,968 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-18 16:12:46,968 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-18 16:12:46,968 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-18 16:12:46,968 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 288340; bufvoid = 104857600\n",
      "2024-02-18 16:12:46,968 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26099064(104396256); length = 115333/6553600\n",
      "2024-02-18 16:12:46,984 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-18 16:12:46,992 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1824884447_0001_m_000002_0 is done. And is in the process of committing\n",
      "2024-02-18 16:12:46,993 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-18 16:12:46,993 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1824884447_0001_m_000002_0' done.\n",
      "2024-02-18 16:12:46,993 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1824884447_0001_m_000002_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72099352\n",
      "\t\tFILE: Number of bytes written=643668\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=185864\n",
      "\t\tMap output records=28834\n",
      "\t\tMap output bytes=288340\n",
      "\t\tMap output materialized bytes=339\n",
      "\t\tInput split bytes=378\n",
      "\t\tCombine input records=28834\n",
      "\t\tCombine output records=24\n",
      "\t\tSpilled Records=24\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=154\n",
      "\t\tTotal committed heap usage (bytes)=720371712\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-18 16:12:46,993 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1824884447_0001_m_000002_0\n",
      "2024-02-18 16:12:46,995 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-18 16:12:47,009 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2024-02-18 16:12:47,009 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1824884447_0001_r_000000_0\n",
      "2024-02-18 16:12:47,020 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:12:47,020 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:12:47,021 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:12:47,021 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:12:47,025 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-18 16:12:47,029 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@404aba7d\n",
      "2024-02-18 16:12:47,033 [pool-4-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:47,070 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-02-18 16:12:47,073 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1824884447_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-02-18 16:12:47,137 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1824884447_0001_m_000000_0 decomp: 451 len: 455 to MEMORY\n",
      "2024-02-18 16:12:47,145 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 451 bytes from map-output for attempt_local1824884447_0001_m_000000_0\n",
      "2024-02-18 16:12:47,146 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 451, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->451\n",
      "2024-02-18 16:12:47,149 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1824884447_0001_m_000001_0 decomp: 451 len: 455 to MEMORY\n",
      "2024-02-18 16:12:47,150 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 451 bytes from map-output for attempt_local1824884447_0001_m_000001_0\n",
      "2024-02-18 16:12:47,150 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 451, inMemoryMapOutputs.size() -> 2, commitMemory -> 451, usedMemory ->902\n",
      "2024-02-18 16:12:47,153 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1824884447_0001_m_000002_0 decomp: 335 len: 339 to MEMORY\n",
      "2024-02-18 16:12:47,156 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 335 bytes from map-output for attempt_local1824884447_0001_m_000002_0\n",
      "2024-02-18 16:12:47,156 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 335, inMemoryMapOutputs.size() -> 3, commitMemory -> 902, usedMemory ->1237\n",
      "2024-02-18 16:12:47,157 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2024-02-18 16:12:47,177 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.\n",
      "2024-02-18 16:12:47,177 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-02-18 16:12:47,187 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 3 sorted segments\n",
      "2024-02-18 16:12:47,188 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 3 segments left of total size: 1216 bytes\n",
      "2024-02-18 16:12:47,192 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 3 segments, 1237 bytes to disk to satisfy reduce memory limit\n",
      "2024-02-18 16:12:47,193 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1237 bytes from disk\n",
      "2024-02-18 16:12:47,194 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-02-18 16:12:47,194 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-18 16:12:47,200 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1226 bytes\n",
      "2024-02-18 16:12:47,200 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.\n",
      "2024-02-18 16:12:47,203 [pool-4-thread-1] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "2024-02-18 16:12:47,203 [pool-4-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-18 16:12:47,204 [pool-4-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-18 16:12:47,206 [pool-4-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: FLIGHTS[6,10],FLIGHTS[-1,-1],DELAYED_FLIGHTS[12,18],COUNT_DELAYED[21,16],GROUPED_DELAYED[18,18],RECOVERED_FLIGHTS[15,20],COUNT_RECOVERED[22,18],GROUPED_RECOVERED[19,20] C: COUNT_DELAYED[21,16],GROUPED_DELAYED[18,18],COUNT_RECOVERED[22,18],GROUPED_RECOVERED[19,20] R: COUNT_DELAYED[21,16],COUNT_RECOVERED[22,18]\n",
      "2024-02-18 16:12:47,209 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:12:47,209 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:12:47,212 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:12:47,212 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:12:47,239 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1824884447_0001_r_000000_0 is done. And is in the process of committing\n",
      "2024-02-18 16:12:47,242 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.\n",
      "2024-02-18 16:12:47,242 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1824884447_0001_r_000000_0 is allowed to commit now\n",
      "2024-02-18 16:12:47,245 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1824884447_0001_r_000000_0' to file:/tmp/temp1004047324/tmp764590971\n",
      "2024-02-18 16:12:47,249 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1824884447_0001_r_000000_0' to file:/tmp/temp1004047324/tmp-420008957\n",
      "2024-02-18 16:12:47,263 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2024-02-18 16:12:47,263 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1824884447_0001_r_000000_0' done.\n",
      "2024-02-18 16:12:47,263 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1824884447_0001_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72101934\n",
      "\t\tFILE: Number of bytes written=645325\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=32\n",
      "\t\tReduce shuffle bytes=1249\n",
      "\t\tReduce input records=88\n",
      "\t\tReduce output records=0\n",
      "\t\tSpilled Records=88\n",
      "\t\tShuffled Maps =3\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=3\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=720371712\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2024-02-18 16:12:47,264 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1824884447_0001_r_000000_0\n",
      "2024-02-18 16:12:47,265 [Thread-6] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-18 16:12:47,428 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 20% complete\n",
      "2024-02-18 16:12:47,431 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:47,441 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:47,442 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "2024-02-18 16:12:47,443 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:47,469 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2024-02-18 16:12:47,470 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2024-02-18 16:12:47,471 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2024-02-18 16:12:47,471 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Using reducer estimator: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator\n",
      "2024-02-18 16:12:47,473 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator - BytesPerReducer=1000000000 maxReducers=999 totalInputFileSize=396\n",
      "2024-02-18 16:12:47,473 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2024-02-18 16:12:47,473 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2024-02-18 16:12:47,493 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2024-02-18 16:12:47,498 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:47,504 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2024-02-18 16:12:47,509 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-18 16:12:47,510 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-02-18 16:12:47,510 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2024-02-18 16:12:47,512 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-18 16:12:47,512 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-02-18 16:12:47,512 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2024-02-18 16:12:47,515 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2\n",
      "2024-02-18 16:12:47,522 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local383870519_0002\n",
      "2024-02-18 16:12:47,523 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2024-02-18 16:12:47,577 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2024-02-18 16:12:47,579 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2024-02-18 16:12:47,583 [Thread-17] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-02-18 16:12:47,583 [Thread-17] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-02-18 16:12:47,583 [Thread-17] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-02-18 16:12:47,584 [Thread-17] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:12:47,584 [Thread-17] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:12:47,584 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2024-02-18 16:12:47,591 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2024-02-18 16:12:47,591 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local383870519_0002_m_000000_0\n",
      "2024-02-18 16:12:47,617 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:12:47,617 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:12:47,617 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-18 16:12:47,620 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 202\n",
      "Input split[0]:\n",
      "   Length = 202\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-18 16:12:47,650 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp1004047324/tmp764590971/part-r-00000:0+202\n",
      "2024-02-18 16:12:47,664 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-18 16:12:47,664 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-18 16:12:47,664 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-18 16:12:47,664 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-18 16:12:47,664 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-18 16:12:47,676 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-18 16:12:47,696 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-18 16:12:47,696 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-18 16:12:47,697 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: JOINED[25,9],JOINED[25,9] C:  R: CALCULATED_PERCENTAGE[28,24]\n",
      "2024-02-18 16:12:47,716 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-18 16:12:47,716 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-18 16:12:47,716 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-18 16:12:47,716 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 186; bufvoid = 104857600\n",
      "2024-02-18 16:12:47,716 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214336(104857344); length = 61/6553600\n",
      "2024-02-18 16:12:47,718 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-18 16:12:47,729 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local383870519_0002_m_000000_0 is done. And is in the process of committing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-18 16:12:47,735 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-18 16:12:47,735 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local383870519_0002_m_000000_0' done.\n",
      "2024-02-18 16:12:47,736 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local383870519_0002_m_000000_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72102982\n",
      "\t\tFILE: Number of bytes written=1257842\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=16\n",
      "\t\tMap output records=16\n",
      "\t\tMap output bytes=186\n",
      "\t\tMap output materialized bytes=224\n",
      "\t\tInput split bytes=377\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=16\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=720371712\n",
      "\tMultiInputCounters\n",
      "\t\tInput records from _0_tmp764590971=16\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-18 16:12:47,736 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local383870519_0002_m_000000_0\n",
      "2024-02-18 16:12:47,736 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local383870519_0002_m_000001_0\n",
      "2024-02-18 16:12:47,770 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:12:47,770 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:12:47,770 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-18 16:12:47,772 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 194\n",
      "Input split[0]:\n",
      "   Length = 194\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-18 16:12:47,774 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp1004047324/tmp-420008957/part-r-00000:0+194\n",
      "2024-02-18 16:12:47,823 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-18 16:12:47,827 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-18 16:12:47,828 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-18 16:12:47,828 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-18 16:12:47,828 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-18 16:12:47,835 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-18 16:12:47,836 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-18 16:12:47,836 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-18 16:12:47,837 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: JOINED[25,9],JOINED[25,9] C:  R: CALCULATED_PERCENTAGE[28,24]\n",
      "2024-02-18 16:12:47,839 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-18 16:12:47,839 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-18 16:12:47,839 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-18 16:12:47,839 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 178; bufvoid = 104857600\n",
      "2024-02-18 16:12:47,839 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214336(104857344); length = 61/6553600\n",
      "2024-02-18 16:12:47,840 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-18 16:12:47,844 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local383870519_0002_m_000001_0 is done. And is in the process of committing\n",
      "2024-02-18 16:12:47,846 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-18 16:12:47,846 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local383870519_0002_m_000001_0' done.\n",
      "2024-02-18 16:12:47,846 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local383870519_0002_m_000001_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72103970\n",
      "\t\tFILE: Number of bytes written=1258090\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=16\n",
      "\t\tMap output records=16\n",
      "\t\tMap output bytes=178\n",
      "\t\tMap output materialized bytes=216\n",
      "\t\tInput split bytes=378\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=16\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=37\n",
      "\t\tTotal committed heap usage (bytes)=719847424\n",
      "\tMultiInputCounters\n",
      "\t\tInput records from _1_tmp-420008957=16\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-18 16:12:47,846 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local383870519_0002_m_000001_0\n",
      "2024-02-18 16:12:47,847 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2024-02-18 16:12:47,848 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2024-02-18 16:12:47,848 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local383870519_0002_r_000000_0\n",
      "2024-02-18 16:12:47,853 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:12:47,853 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:12:47,855 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-18 16:12:47,855 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3a6fa37f\n",
      "2024-02-18 16:12:47,855 [pool-9-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:47,856 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-02-18 16:12:47,860 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local383870519_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-02-18 16:12:47,875 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local383870519_0002_m_000001_0 decomp: 212 len: 216 to MEMORY\n",
      "2024-02-18 16:12:47,878 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 212 bytes from map-output for attempt_local383870519_0002_m_000001_0\n",
      "2024-02-18 16:12:47,880 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 212, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->212\n",
      "2024-02-18 16:12:47,885 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local383870519_0002_m_000000_0 decomp: 220 len: 224 to MEMORY\n",
      "2024-02-18 16:12:47,888 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 220 bytes from map-output for attempt_local383870519_0002_m_000000_0\n",
      "2024-02-18 16:12:47,888 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 220, inMemoryMapOutputs.size() -> 2, commitMemory -> 212, usedMemory ->432\n",
      "2024-02-18 16:12:47,895 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-18 16:12:47,929 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.\n",
      "2024-02-18 16:12:47,929 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-02-18 16:12:47,930 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 2 sorted segments\n",
      "2024-02-18 16:12:47,942 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 2 segments left of total size: 418 bytes\n",
      "2024-02-18 16:12:47,944 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 432 bytes to disk to satisfy reduce memory limit\n",
      "2024-02-18 16:12:47,944 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 434 bytes from disk\n",
      "2024-02-18 16:12:47,945 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-02-18 16:12:47,945 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-18 16:12:47,945 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 423 bytes\n",
      "2024-02-18 16:12:47,946 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.\n",
      "2024-02-18 16:12:47,953 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:12:47,953 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:12:47,955 [pool-9-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-18 16:12:47,956 [pool-9-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-18 16:12:47,957 [pool-9-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: JOINED[25,9],JOINED[25,9] C:  R: CALCULATED_PERCENTAGE[28,24]\n",
      "2024-02-18 16:12:47,975 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local383870519_0002_r_000000_0 is done. And is in the process of committing\n",
      "2024-02-18 16:12:47,976 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.\n",
      "2024-02-18 16:12:47,976 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local383870519_0002_r_000000_0 is allowed to commit now\n",
      "2024-02-18 16:12:47,977 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local383870519_0002_r_000000_0' to file:/tmp/temp1004047324/tmp-241268372\n",
      "2024-02-18 16:12:48,001 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local383870519_0002\n",
      "2024-02-18 16:12:48,001 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases CALCULATED_PERCENTAGE,JOINED\n",
      "2024-02-18 16:12:48,001 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: JOINED[25,9],JOINED[25,9] C:  R: CALCULATED_PERCENTAGE[28,24]\n",
      "2024-02-18 16:12:48,016 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 30% complete\n",
      "2024-02-18 16:12:48,016 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local383870519_0002]\n",
      "2024-02-18 16:12:48,019 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2024-02-18 16:12:48,019 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local383870519_0002_r_000000_0' done.\n",
      "2024-02-18 16:12:48,019 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local383870519_0002_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72104908\n",
      "\t\tFILE: Number of bytes written=1258760\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=16\n",
      "\t\tReduce shuffle bytes=440\n",
      "\t\tReduce input records=32\n",
      "\t\tReduce output records=16\n",
      "\t\tSpilled Records=32\n",
      "\t\tShuffled Maps =2\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=719847424\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2024-02-18 16:12:48,019 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local383870519_0002_r_000000_0\n",
      "2024-02-18 16:12:48,019 [Thread-17] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2024-02-18 16:12:48,225 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 40% complete\n",
      "2024-02-18 16:12:48,226 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:48,227 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:48,228 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:48,240 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2024-02-18 16:12:48,240 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2024-02-18 16:12:48,243 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2024-02-18 16:12:48,244 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Using reducer estimator: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator\n",
      "2024-02-18 16:12:48,247 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator - BytesPerReducer=1000000000 maxReducers=999 totalInputFileSize=224\n",
      "2024-02-18 16:12:48,248 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2024-02-18 16:12:48,253 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2024-02-18 16:12:48,262 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2024-02-18 16:12:48,270 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:48,273 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2024-02-18 16:12:48,274 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-18 16:12:48,274 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-02-18 16:12:48,274 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2024-02-18 16:12:48,276 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2024-02-18 16:12:48,288 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local956614009_0003\n",
      "2024-02-18 16:12:48,288 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-18 16:12:48,353 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2024-02-18 16:12:48,364 [Thread-25] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2024-02-18 16:12:48,367 [Thread-25] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-02-18 16:12:48,367 [Thread-25] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-02-18 16:12:48,367 [Thread-25] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-02-18 16:12:48,367 [Thread-25] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:12:48,368 [Thread-25] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:12:48,368 [Thread-25] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2024-02-18 16:12:48,405 [Thread-25] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2024-02-18 16:12:48,405 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local956614009_0003_m_000000_0\n",
      "2024-02-18 16:12:48,416 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:12:48,416 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:12:48,417 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-18 16:12:48,418 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 224\n",
      "Input split[0]:\n",
      "   Length = 224\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-18 16:12:48,419 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp1004047324/tmp-241268372/part-r-00000:0+224\n",
      "2024-02-18 16:12:48,423 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-18 16:12:48,423 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-18 16:12:48,423 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-18 16:12:48,423 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-18 16:12:48,423 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-18 16:12:48,443 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-18 16:12:48,445 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-18 16:12:48,445 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-18 16:12:48,445 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: ORDERED_RECOVERY[33,19] C:  R: \n",
      "2024-02-18 16:12:48,453 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-18 16:12:48,453 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-18 16:12:48,453 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-18 16:12:48,453 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 352; bufvoid = 104857600\n",
      "2024-02-18 16:12:48,453 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214336(104857344); length = 61/6553600\n",
      "2024-02-18 16:12:48,456 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-18 16:12:48,469 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local956614009_0003_m_000000_0 is done. And is in the process of committing\n",
      "2024-02-18 16:12:48,485 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-18 16:12:48,485 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local956614009_0003_m_000000_0' done.\n",
      "2024-02-18 16:12:48,485 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local956614009_0003_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72105581\n",
      "\t\tFILE: Number of bytes written=1872946\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=16\n",
      "\t\tMap output records=16\n",
      "\t\tMap output bytes=352\n",
      "\t\tMap output materialized bytes=390\n",
      "\t\tInput split bytes=378\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=16\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=719847424\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-18 16:12:48,485 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local956614009_0003_m_000000_0\n",
      "2024-02-18 16:12:48,488 [Thread-25] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2024-02-18 16:12:48,498 [Thread-25] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2024-02-18 16:12:48,498 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local956614009_0003_r_000000_0\n",
      "2024-02-18 16:12:48,532 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:12:48,532 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:12:48,533 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-18 16:12:48,533 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@59093cd4\n",
      "2024-02-18 16:12:48,533 [pool-12-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:48,535 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-02-18 16:12:48,538 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local956614009_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-02-18 16:12:48,551 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#3 about to shuffle output of map attempt_local956614009_0003_m_000000_0 decomp: 386 len: 390 to MEMORY\n",
      "2024-02-18 16:12:48,551 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 386 bytes from map-output for attempt_local956614009_0003_m_000000_0\n",
      "2024-02-18 16:12:48,551 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 386, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->386\n",
      "2024-02-18 16:12:48,584 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2024-02-18 16:12:48,587 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-18 16:12:48,587 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-02-18 16:12:48,600 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-18 16:12:48,600 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 370 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-18 16:12:48,616 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 386 bytes to disk to satisfy reduce memory limit\n",
      "2024-02-18 16:12:48,617 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 390 bytes from disk\n",
      "2024-02-18 16:12:48,617 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-02-18 16:12:48,617 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-18 16:12:48,618 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 370 bytes\n",
      "2024-02-18 16:12:48,618 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-18 16:12:48,619 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:12:48,619 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:12:48,620 [pool-12-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-18 16:12:48,620 [pool-12-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-18 16:12:48,622 [pool-12-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: ORDERED_RECOVERY[33,19] C:  R: \n",
      "2024-02-18 16:12:48,623 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local956614009_0003_r_000000_0 is done. And is in the process of committing\n",
      "2024-02-18 16:12:48,624 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-18 16:12:48,624 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local956614009_0003_r_000000_0 is allowed to commit now\n",
      "2024-02-18 16:12:48,625 [pool-12-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local956614009_0003_r_000000_0' to file:/tmp/temp1004047324/tmp-840604375\n",
      "2024-02-18 16:12:48,638 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2024-02-18 16:12:48,638 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local956614009_0003_r_000000_0' done.\n",
      "2024-02-18 16:12:48,638 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local956614009_0003_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72106393\n",
      "\t\tFILE: Number of bytes written=1873401\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce shuffle bytes=390\n",
      "\t\tReduce input records=16\n",
      "\t\tReduce output records=1\n",
      "\t\tSpilled Records=16\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=719847424\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2024-02-18 16:12:48,638 [pool-12-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local956614009_0003_r_000000_0\n",
      "2024-02-18 16:12:48,639 [Thread-25] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2024-02-18 16:12:48,763 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local956614009_0003\n",
      "2024-02-18 16:12:48,763 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases ORDERED_RECOVERY\n",
      "2024-02-18 16:12:48,763 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: ORDERED_RECOVERY[33,19] C:  R: \n",
      "2024-02-18 16:12:48,764 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 60% complete\n",
      "2024-02-18 16:12:48,765 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:48,766 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:48,766 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:48,812 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2024-02-18 16:12:48,816 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2024-02-18 16:12:48,817 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2024-02-18 16:12:48,817 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2024-02-18 16:12:48,821 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2024-02-18 16:12:48,847 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2024-02-18 16:12:48,864 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:48,884 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2024-02-18 16:12:48,892 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-18 16:12:48,895 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-02-18 16:12:48,895 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2024-02-18 16:12:48,900 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2024-02-18 16:12:48,917 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1946139539_0004\n",
      "2024-02-18 16:12:48,919 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2024-02-18 16:12:49,049 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2024-02-18 16:12:49,070 [Thread-32] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2024-02-18 16:12:49,073 [Thread-32] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-02-18 16:12:49,074 [Thread-32] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-02-18 16:12:49,074 [Thread-32] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-02-18 16:12:49,074 [Thread-32] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:12:49,074 [Thread-32] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:12:49,074 [Thread-32] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-18 16:12:49,104 [Thread-32] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2024-02-18 16:12:49,104 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1946139539_0004_m_000000_0\n",
      "2024-02-18 16:12:49,124 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:12:49,124 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:12:49,125 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-18 16:12:49,125 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 224\n",
      "Input split[0]:\n",
      "   Length = 224\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-18 16:12:49,126 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp1004047324/tmp-241268372/part-r-00000:0+224\n",
      "2024-02-18 16:12:49,134 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-18 16:12:49,134 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-18 16:12:49,134 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-18 16:12:49,134 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-18 16:12:49,134 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-18 16:12:49,141 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-18 16:12:49,149 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-18 16:12:49,149 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-18 16:12:49,149 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: ORDERED_RECOVERY[33,19] C:  R: \n",
      "2024-02-18 16:12:49,150 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-18 16:12:49,150 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-18 16:12:49,150 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-18 16:12:49,150 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 224; bufvoid = 104857600\n",
      "2024-02-18 16:12:49,150 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214336(104857344); length = 61/6553600\n",
      "2024-02-18 16:12:49,165 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-18 16:12:49,172 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1946139539_0004_m_000000_0 is done. And is in the process of committing\n",
      "2024-02-18 16:12:49,174 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-18 16:12:49,174 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1946139539_0004_m_000000_0' done.\n",
      "2024-02-18 16:12:49,174 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1946139539_0004_m_000000_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72107066\n",
      "\t\tFILE: Number of bytes written=2496062\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=16\n",
      "\t\tMap output records=16\n",
      "\t\tMap output bytes=224\n",
      "\t\tMap output materialized bytes=86\n",
      "\t\tInput split bytes=378\n",
      "\t\tCombine input records=16\n",
      "\t\tCombine output records=5\n",
      "\t\tSpilled Records=5\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=720371712\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-18 16:12:49,174 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1946139539_0004_m_000000_0\n",
      "2024-02-18 16:12:49,174 [Thread-32] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2024-02-18 16:12:49,178 [Thread-32] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2024-02-18 16:12:49,178 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1946139539_0004_r_000000_0\n",
      "2024-02-18 16:12:49,185 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:12:49,185 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:12:49,195 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-18 16:12:49,195 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1f4c6cef\n",
      "2024-02-18 16:12:49,195 [pool-15-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:49,202 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-02-18 16:12:49,209 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1946139539_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-02-18 16:12:49,212 [localfetcher#4] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#4 about to shuffle output of map attempt_local1946139539_0004_m_000000_0 decomp: 82 len: 86 to MEMORY\n",
      "2024-02-18 16:12:49,212 [localfetcher#4] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 82 bytes from map-output for attempt_local1946139539_0004_m_000000_0\n",
      "2024-02-18 16:12:49,212 [localfetcher#4] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 82, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->82\n",
      "2024-02-18 16:12:49,223 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2024-02-18 16:12:49,224 [Readahead Thread #1] WARN  org.apache.hadoop.io.ReadaheadPool - Failed readahead on ifile\n",
      "EBADF: Bad file descriptor\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:419)\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:296)\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:220)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "2024-02-18 16:12:49,226 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-18 16:12:49,229 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-02-18 16:12:49,237 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-18 16:12:49,239 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 74 bytes\n",
      "2024-02-18 16:12:49,260 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 82 bytes to disk to satisfy reduce memory limit\n",
      "2024-02-18 16:12:49,261 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 86 bytes from disk\n",
      "2024-02-18 16:12:49,261 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-02-18 16:12:49,261 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-18 16:12:49,262 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 74 bytes\n",
      "2024-02-18 16:12:49,262 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-18 16:12:49,263 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:12:49,263 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:12:49,264 [pool-15-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-18 16:12:49,265 [pool-15-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-18 16:12:49,266 [pool-15-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: ORDERED_RECOVERY[33,19] C:  R: \n",
      "2024-02-18 16:12:49,266 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1946139539_0004_r_000000_0 is done. And is in the process of committing\n",
      "2024-02-18 16:12:49,268 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-18 16:12:49,268 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1946139539_0004_r_000000_0 is allowed to commit now\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-18 16:12:49,270 [pool-15-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1946139539_0004_r_000000_0' to file:/tmp/temp1004047324/tmp-1394609891\n",
      "2024-02-18 16:12:49,280 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2024-02-18 16:12:49,280 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1946139539_0004_r_000000_0' done.\n",
      "2024-02-18 16:12:49,282 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1946139539_0004_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72107270\n",
      "\t\tFILE: Number of bytes written=2496230\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=5\n",
      "\t\tReduce shuffle bytes=86\n",
      "\t\tReduce input records=5\n",
      "\t\tReduce output records=5\n",
      "\t\tSpilled Records=5\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=720371712\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2024-02-18 16:12:49,288 [pool-15-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1946139539_0004_r_000000_0\n",
      "2024-02-18 16:12:49,292 [Thread-32] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2024-02-18 16:12:49,356 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local1946139539_0004\n",
      "2024-02-18 16:12:49,356 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases ORDERED_RECOVERY\n",
      "2024-02-18 16:12:49,356 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: ORDERED_RECOVERY[33,19] C:  R: \n",
      "2024-02-18 16:12:49,357 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 80% complete\n",
      "2024-02-18 16:12:49,357 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_local1946139539_0004]\n",
      "2024-02-18 16:12:49,472 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:49,473 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:49,476 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:49,485 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2024-02-18 16:12:49,486 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2024-02-18 16:12:49,488 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2024-02-18 16:12:49,488 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2024-02-18 16:12:49,489 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2024-02-18 16:12:49,496 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2024-02-18 16:12:49,499 [JobControl] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:49,503 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2024-02-18 16:12:49,505 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-18 16:12:49,505 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2024-02-18 16:12:49,505 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2024-02-18 16:12:49,506 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2024-02-18 16:12:49,519 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local743114634_0005\n",
      "2024-02-18 16:12:49,519 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2024-02-18 16:12:49,565 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2024-02-18 16:12:49,574 [Thread-39] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2024-02-18 16:12:49,578 [Thread-39] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2024-02-18 16:12:49,578 [Thread-39] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-02-18 16:12:49,578 [Thread-39] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2024-02-18 16:12:49,578 [Thread-39] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:12:49,578 [Thread-39] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:12:49,579 [Thread-39] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2024-02-18 16:12:49,593 [Thread-39] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2024-02-18 16:12:49,593 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local743114634_0005_m_000000_0\n",
      "2024-02-18 16:12:49,600 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:12:49,601 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:12:49,601 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-18 16:12:49,606 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 70\n",
      "Input split[0]:\n",
      "   Length = 70\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2024-02-18 16:12:49,609 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader - Current split being processed file:/tmp/temp1004047324/tmp-1394609891/part-r-00000:0+70\n",
      "2024-02-18 16:12:49,620 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-02-18 16:12:49,620 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2024-02-18 16:12:49,620 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2024-02-18 16:12:49,620 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2024-02-18 16:12:49,620 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2024-02-18 16:12:49,632 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-02-18 16:12:49,633 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-18 16:12:49,633 [LocalJobRunner Map Task Executor #0] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-18 16:12:49,637 [LocalJobRunner Map Task Executor #0] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigGenericMapReduce$Map - Aliases being processed per job phase (AliasName[line,offset]): M: ORDERED_RECOVERY[33,19] C:  R: \n",
      "2024-02-18 16:12:49,640 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2024-02-18 16:12:49,640 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2024-02-18 16:12:49,640 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2024-02-18 16:12:49,640 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 70; bufvoid = 104857600\n",
      "2024-02-18 16:12:49,640 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214380(104857520); length = 17/6553600\n",
      "2024-02-18 16:12:49,641 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2024-02-18 16:12:49,643 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local743114634_0005_m_000000_0 is done. And is in the process of committing\n",
      "2024-02-18 16:12:49,680 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2024-02-18 16:12:49,680 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local743114634_0005_m_000000_0' done.\n",
      "2024-02-18 16:12:49,680 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local743114634_0005_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72107789\n",
      "\t\tFILE: Number of bytes written=3104274\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=5\n",
      "\t\tMap output records=5\n",
      "\t\tMap output bytes=70\n",
      "\t\tMap output materialized bytes=86\n",
      "\t\tInput split bytes=379\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=5\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=720371712\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2024-02-18 16:12:49,680 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local743114634_0005_m_000000_0\n",
      "2024-02-18 16:12:49,680 [Thread-39] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2024-02-18 16:12:49,685 [Thread-39] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2024-02-18 16:12:49,686 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local743114634_0005_r_000000_0\n",
      "2024-02-18 16:12:49,689 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:12:49,691 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-18 16:12:49,696 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-02-18 16:12:49,698 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@50efb789\n",
      "2024-02-18 16:12:49,698 [pool-18-thread-1] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:49,700 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-02-18 16:12:49,704 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local743114634_0005_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-02-18 16:12:49,709 [localfetcher#5] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#5 about to shuffle output of map attempt_local743114634_0005_m_000000_0 decomp: 82 len: 86 to MEMORY\n",
      "2024-02-18 16:12:49,709 [localfetcher#5] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 82 bytes from map-output for attempt_local743114634_0005_m_000000_0\n",
      "2024-02-18 16:12:49,709 [localfetcher#5] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 82, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->82\n",
      "2024-02-18 16:12:49,713 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2024-02-18 16:12:49,724 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-18 16:12:49,726 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-02-18 16:12:49,728 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-18 16:12:49,728 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 74 bytes\n",
      "2024-02-18 16:12:49,731 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 82 bytes to disk to satisfy reduce memory limit\n",
      "2024-02-18 16:12:49,732 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 86 bytes from disk\n",
      "2024-02-18 16:12:49,732 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-02-18 16:12:49,732 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2024-02-18 16:12:49,732 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 74 bytes\n",
      "2024-02-18 16:12:49,733 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-18 16:12:49,737 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2\n",
      "2024-02-18 16:12:49,738 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-02-18 16:12:49,741 [pool-18-thread-1] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2024-02-18 16:12:49,748 [pool-18-thread-1] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-18 16:12:49,749 [pool-18-thread-1] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapReduce$Reduce - Aliases being processed per job phase (AliasName[line,offset]): M: ORDERED_RECOVERY[33,19] C:  R: \n",
      "2024-02-18 16:12:49,749 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local743114634_0005_r_000000_0 is done. And is in the process of committing\n",
      "2024-02-18 16:12:49,753 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2024-02-18 16:12:49,757 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local743114634_0005_r_000000_0 is allowed to commit now\n",
      "2024-02-18 16:12:49,760 [pool-18-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local743114634_0005_r_000000_0' to file:/tmp/temp1004047324/tmp767834596\n",
      "2024-02-18 16:12:49,771 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2024-02-18 16:12:49,771 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local743114634_0005_r_000000_0' done.\n",
      "2024-02-18 16:12:49,772 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local743114634_0005_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=72107993\n",
      "\t\tFILE: Number of bytes written=3104442\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=5\n",
      "\t\tReduce shuffle bytes=86\n",
      "\t\tReduce input records=5\n",
      "\t\tReduce output records=5\n",
      "\t\tSpilled Records=5\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=720371712\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2024-02-18 16:12:49,772 [pool-18-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local743114634_0005_r_000000_0\n",
      "2024-02-18 16:12:49,772 [Thread-39] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2024-02-18 16:12:50,001 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_local743114634_0005\n",
      "2024-02-18 16:12:50,002 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases ORDERED_RECOVERY\n",
      "2024-02-18 16:12:50,002 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: ORDERED_RECOVERY[33,19] C:  R: \n",
      "2024-02-18 16:12:50,003 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:50,004 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:50,008 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:50,033 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 100% complete\n",
      "2024-02-18 16:12:50,040 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats - Script Statistics: \n",
      "\n",
      "HadoopVersion\tPigVersion\tUserId\tStartedAt\tFinishedAt\tFeatures\n",
      "3.3.1\t0.17.0\troot\t2024-02-18 16:12:39\t2024-02-18 16:12:50\tHASH_JOIN,GROUP_BY,ORDER_BY,FILTER,LIMIT\n",
      "\n",
      "Success!\n",
      "\n",
      "Job Stats (time in seconds):\n",
      "JobId\tMaps\tReduces\tMaxMapTime\tMinMapTime\tAvgMapTime\tMedianMapTime\tMaxReduceTime\tMinReduceTime\tAvgReduceTime\tMedianReducetime\tAlias\tFeature\tOutputs\n",
      "job_local1824884447_0001\t3\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tCOUNT_DELAYED,COUNT_RECOVERED,DELAYED_FLIGHTS,FLIGHTS,GROUPED_DELAYED,GROUPED_RECOVERED,RECOVERED_FLIGHTS\tMULTI_QUERY,COMBINER\t\n",
      "job_local1946139539_0004\t1\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tORDERED_RECOVERY\tORDER_BY,COMBINER\t\n",
      "job_local383870519_0002\t2\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tCALCULATED_PERCENTAGE,JOINED\tHASH_JOIN\t\n",
      "job_local743114634_0005\t1\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tORDERED_RECOVERY\t\tfile:/tmp/temp1004047324/tmp767834596,\n",
      "job_local956614009_0003\t1\t1\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tn/a\tORDERED_RECOVERY\tSAMPLER\t\n",
      "\n",
      "Input(s):\n",
      "Successfully read 2702218 records from: \"file:///media/notebooks/Tarea 3/notebooks/flights.csv\"\n",
      "\n",
      "Output(s):\n",
      "Successfully stored 5 records in: \"file:/tmp/temp1004047324/tmp767834596\"\n",
      "\n",
      "Counters:\n",
      "Total records written : 5\n",
      "Total bytes written : 0\n",
      "Spillable Memory Manager spill count : 0\n",
      "Total bags proactively spilled: 0\n",
      "Total records proactively spilled: 0\n",
      "\n",
      "Job DAG:\n",
      "job_local1824884447_0001\t->\tjob_local383870519_0002,\n",
      "job_local383870519_0002\t->\tjob_local956614009_0003,\n",
      "job_local956614009_0003\t->\tjob_local1946139539_0004,\n",
      "job_local1946139539_0004\t->\tjob_local743114634_0005,\n",
      "job_local743114634_0005\n",
      "\n",
      "\n",
      "2024-02-18 16:12:50,041 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:50,041 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:50,042 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:50,073 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-18 16:12:50,078 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:50,081 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:50,083 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:50,083 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:50,084 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:50,089 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:50,091 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:50,092 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:50,097 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:50,100 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:50,102 [main] WARN  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!\n",
      "2024-02-18 16:12:50,110 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Success!\n",
      "2024-02-18 16:12:50,112 [main] WARN  org.apache.pig.data.SchemaTupleBackend - SchemaTupleBackend has already been initialized\n",
      "2024-02-18 16:12:50,113 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2024-02-18 16:12:50,113 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "(UA,0.245073)\n",
      "(WN,0.23570879)\n",
      "(FL,0.22657289)\n",
      "(DL,0.21578781)\n",
      "(AA,0.20162015)\n",
      "2024-02-18 16:12:50,161 [main] INFO  org.apache.pig.Main - Pig script completed in 11 seconds and 789 milliseconds (11789 ms)\n"
     ]
    }
   ],
   "source": [
    "! pig -x local -f ejercicio3.pig -param airports_file='airports.csv' -param flights_file='flights.csv' -param output_dir='pig/output/flights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
